from __future__ import annotations

"""
ë©€í‹° ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
Master Agent â†’ ì„œë¸Œ ì—ì´ì „íŠ¸ë“¤ì˜ í˜‘ì—… ê³¼ì •ì„ ì‹œê°í™”
"""
import json
import logging
import uuid
from typing import AsyncGenerator, Optional, List, Any

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig

from src.agents.graph_master import build_graph
from src.services.user_profile_service import user_profile_service
from src.services import chat_history_service
from src.services.hitl_interrupt_service import handle_hitl_interrupt
from src.models.database import get_db_context
from src.utils.hitl_compat import automation_level_to_hitl_config
from src.config.settings import settings

logger = logging.getLogger(__name__)

router = APIRouter()


class MultiAgentStreamRequest(BaseModel):
    """ë©€í‹° ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­"""
    message: str
    user_id: Optional[str] = None
    conversation_id: Optional[str] = None
    automation_level: int = Field(default=2, ge=1, le=3)
    stream_thinking: bool = Field(default=True, description="LLM ì‚¬ê³  ê³¼ì • ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™” (ChatGPTì‹)")


def _sse(event: str, payload: dict) -> str:
    return f"event: {event}\ndata: {json.dumps(payload, ensure_ascii=False)}\n\n"


def _event_agent_name(event: dict) -> Optional[str]:
    metadata = event.get("metadata") or {}
    node = metadata.get("langgraph_node")
    if node and node != "LangGraph":
        return node
    name = event.get("name")
    if name and name != "LangGraph":
        return name
    return None


def _normalize_output(raw_output: Any) -> dict:
    """LangGraph ì´ë²¤íŠ¸ outputì„ dictë¡œ ì •ê·œí™”í•´ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë¡œì§ì„ ë³´í˜¸."""
    if raw_output is None:
        return {}
    if isinstance(raw_output, dict):
        return raw_output
    if hasattr(raw_output, "model_dump"):
        try:
            return raw_output.model_dump()
        except Exception:
            pass
    if hasattr(raw_output, "dict"):
        try:
            return raw_output.dict()
        except Exception:
            pass
    content = getattr(raw_output, "content", None)
    if isinstance(content, dict):
        return content
    if content is not None:
        return {"message": content}
    return {}


def _event_to_sse_chunks(event: dict, stream_thinking: bool) -> List[str]:
    chunks: List[str] = []
    event_type = event.get("event")
    agent = _event_agent_name(event)

    if event_type == "on_chain_start" and agent:
        if agent == "routing":
            chunks.append(_sse("master_routing", {"status": "analyzing"}))
        elif agent == "worker_dispatch":
            chunks.append(_sse("worker_start", {"agent": "worker"}))
        else:
            chunks.append(_sse("agent_start", {"agent": agent}))

    elif event_type == "on_chain_end" and agent:
        output = _normalize_output(event.get("data", {}).get("output"))
        if agent == "routing":
            chunks.append(
                _sse(
                    "master_routing",
                    {
                        "agents": output.get("agents_to_call", []),
                        "depth_level": output.get("depth_level"),
                        "worker_action": output.get("worker_action"),
                    },
                )
            )
        elif agent == "worker_dispatch":
            chunks.append(
                _sse(
                    "worker_complete",
                    {"result": output.get("final_response", {}), "agent": "worker"},
                )
            )
        elif agent == "clarification":
            chunks.append(
                _sse(
                    "master_complete",
                    {"message": output.get("final_response", {}).get("message")},
                )
            )
        else:
            chunks.append(_sse("agent_complete", {"agent": agent}))

    elif event_type == "on_chat_model_start" and agent:
        model = event.get("name") or event.get("data", {}).get("name")
        chunks.append(_sse("agent_llm_start", {"agent": agent, "model": model}))

    elif event_type == "on_chat_model_stream" and stream_thinking:
        chunk = event.get("data", {}).get("chunk")
        if chunk:
            content = chunk.get("content") if isinstance(chunk, dict) else str(chunk)
            if content:
                chunks.append(_sse("agent_thinking", {"agent": agent, "content": content}))

    elif event_type == "on_chat_model_end" and agent:
        chunks.append(_sse("agent_llm_end", {"agent": agent}))

    return chunks


def _extract_final_message(state_values: dict) -> str:
    final_response = state_values.get("final_response") or {}
    if isinstance(final_response, dict):
        message = final_response.get("message")
        if isinstance(message, str) and message.strip():
            return message

    messages = state_values.get("messages") or []
    for msg in reversed(messages):
        content = getattr(msg, "content", None)
        if isinstance(content, str) and content.strip():
            return content
        if isinstance(content, list):
            text = "".join(
                part.get("text", "")
                for part in content
                if isinstance(part, dict) and part.get("type") == "text"
            )
            if text.strip():
                return text

    return "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."


async def stream_multi_agent_execution(
    message: str,
    user_id: str,
    conversation_id: str,
    automation_level: int,
    stream_thinking: bool = True
) -> AsyncGenerator[str, None]:
    """LangGraph Supervisor ì‹¤í–‰ì„ SSEë¡œ ë˜í•‘"""
    try:
        yield _sse("master_start", {"message": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."})

        with get_db_context() as db:
            user_profile = user_profile_service.get_user_profile(user_id, db)

        yield _sse("user_profile", {"profile_loaded": True})

        conversation_uuid = uuid.UUID(conversation_id)
        demo_user_uuid = settings.demo_user_uuid
        hitl_config = automation_level_to_hitl_config(automation_level)

        await chat_history_service.upsert_session(
            conversation_id=conversation_uuid,
            user_id=demo_user_uuid,
            automation_level=automation_level,
            metadata={"hitl_preset": hitl_config.preset},
        )
        await chat_history_service.append_message(
            conversation_id=conversation_uuid,
            role="user",
            content=message,
        )

        conversation_history: list[dict] = []
        try:
            history_data = await chat_history_service.get_history(conversation_id=conversation_uuid, limit=10)
            if history_data and "messages" in history_data:
                messages = history_data["messages"][:-1]
                conversation_history = [
                    {"role": msg.role, "content": msg.content}
                    for msg in messages[-6:]
                ]
        except Exception as history_error:  # pragma: no cover - íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
            logger.warning("âš ï¸ [MultiAgentStream] ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: %s", history_error)

        app = build_graph(automation_level=automation_level)
        config: RunnableConfig = {"configurable": {"thread_id": conversation_id}}
        configured_app = app.with_config(config)

        initial_state = {
            "messages": [HumanMessage(content=message)],
            "user_id": user_id or str(demo_user_uuid),
            "conversation_id": conversation_id,
            "hitl_config": hitl_config.model_dump(),
            "automation_level": automation_level,
            "user_profile": user_profile,
            "intent": None,
            "query": message,
            "agent_results": {},
            "agents_to_call": [],
            "agents_called": [],
            "risk_level": None,
            "hitl_required": False,
            "trade_prepared": False,
            "trade_approved": False,
            "trade_executed": False,
            "trade_order_id": None,
            "trade_result": None,
            "summary": None,
            "final_response": None,
            "conversation_history": conversation_history,
        }

        async for event in configured_app.astream_events(initial_state, version="v2"):
            for chunk in _event_to_sse_chunks(event, stream_thinking):
                yield chunk

        state = await configured_app.aget_state()
        pending_nodes = getattr(state, "next", None)

        if pending_nodes:
            logger.info("âš ï¸ [MultiAgentStream] Interrupt ê°ì§€: next=%s", pending_nodes)
            with get_db_context() as db:
                hitl_result = await handle_hitl_interrupt(
                    state=state,
                    conversation_uuid=conversation_uuid,
                    conversation_id=conversation_id,
                    user_id=demo_user_uuid,
                    db=db,
                    automation_level=automation_level,
                    hitl_config=hitl_config,
                )

            if hitl_result:
                yield _sse(
                    "hitl_interrupt",
                    {
                        "pending_nodes": pending_nodes,
                        "approval_request": hitl_result["approval_request"],
                        "message": hitl_result["message"],
                    },
                )
                yield _sse(
                    "master_complete",
                    {"message": hitl_result["message"], "conversation_id": conversation_id},
                )
                yield _sse("done", {"conversation_id": conversation_id})
                return
            else:  # pragma: no cover - ì˜ˆì™¸ì ì¸ ì‹¤íŒ¨
                logger.warning("âš ï¸ [MultiAgentStream] HITL í—¬í¼ ì‹¤í–‰ ì‹¤íŒ¨ - ê¸°ë³¸ ì´ë²¤íŠ¸ë§Œ ì „ì†¡")
                yield _sse(
                    "hitl_interrupt",
                    {
                        "pending_nodes": pending_nodes,
                        "tasks": [getattr(task, "__dict__", str(task)) for task in getattr(state, "tasks", [])],
                    },
                )

        values = getattr(state, "values", {})
        final_message = _extract_final_message(values)

        await chat_history_service.append_message(
            conversation_id=conversation_uuid,
            role="assistant",
            content=final_message,
            metadata={"source": "graph"},
        )

        yield _sse("master_complete", {"message": final_message, "conversation_id": conversation_id})
        yield _sse("done", {"conversation_id": conversation_id})

    except Exception as exc:  # pragma: no cover - SSE ê²½ë¡œ ì˜¤ë¥˜ ì²˜ë¦¬
        logger.exception("âŒ [MultiAgentStream] ì‹¤í–‰ ì‹¤íŒ¨: %s", exc)
        error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤. ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}"
        yield _sse("error", {"error": str(exc), "message": error_message})
        yield _sse("done", {"conversation_id": conversation_id})


@router.post("/multi-stream")
async def multi_agent_stream(request: MultiAgentStreamRequest):
    """
    ë©€í‹° ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°

    **Master Agentê°€ ì—¬ëŸ¬ ì„œë¸Œ ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ëŠ” ê³¼ì •ì„ ì‹œê°í™”**

    **ì‘ë‹µ í˜•ì‹: Server-Sent Events (SSE)**

    **ì´ë²¤íŠ¸ íƒ€ì…:**
    - `master_start`: Master Agent ì‹œì‘
    - `master_routing`: ì–´ë–¤ ì—ì´ì „íŠ¸ë“¤ì„ í˜¸ì¶œí• ì§€ ê²°ì •
    - `agent_start`: ì„œë¸Œ ì—ì´ì „íŠ¸ ì‹œì‘
    - `agent_node`: ì—ì´ì „íŠ¸ ë‚´ë¶€ ë…¸ë“œ ì‹¤í–‰ ìƒíƒœ
    - `agent_llm_start`: LLM í˜¸ì¶œ ì‹œì‘
    - `agent_llm_end`: LLM í˜¸ì¶œ ì™„ë£Œ
    - `agent_complete`: ì„œë¸Œ ì—ì´ì „íŠ¸ ì™„ë£Œ
    - `master_aggregating`: Masterê°€ ê²°ê³¼ ì§‘ê³„ ì¤‘
    - `master_complete`: ì „ì²´ ì™„ë£Œ
    - `error`: ì—ëŸ¬ ë°œìƒ
    - `done`: ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ

    **Frontend ì‚¬ìš© ì˜ˆì‹œ (React):**
    ```javascript
    const [agentStatus, setAgentStatus] = useState({});

    const eventSource = new EventSource('/api/v1/chat/multi-stream', {
        method: 'POST',
        body: JSON.stringify({
            message: 'ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜',
            user_id: 'user123'
        })
    });

    eventSource.addEventListener('master_routing', (event) => {
        const data = JSON.parse(event.data);
        console.log('í˜¸ì¶œí•  ì—ì´ì „íŠ¸:', data.agents);
        // UIì— í‘œì‹œ: Research, Strategy, Risk ì—ì´ì „íŠ¸ í™œì„±í™”
    });

    eventSource.addEventListener('agent_start', (event) => {
        const data = JSON.parse(event.data);
        setAgentStatus(prev => ({
            ...prev,
            [data.agent]: 'running'
        }));
        // UI: Research Agent ì¹´ë“œì— "ì‹¤í–‰ ì¤‘" í‘œì‹œ
    });

    eventSource.addEventListener('agent_node', (event) => {
        const data = JSON.parse(event.data);
        console.log(`${data.agent} - ${data.node}: ${data.status}`);
        // UI: "ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", "Bull ë¶„ì„ ì¤‘..." ë“± í‘œì‹œ
    });

    eventSource.addEventListener('agent_complete', (event) => {
        const data = JSON.parse(event.data);
        setAgentStatus(prev => ({
            ...prev,
            [data.agent]: 'complete'
        }));
        console.log('ê²°ê³¼:', data.result);
        // UI: Research Agent ì¹´ë“œì— "ì™„ë£Œ" + ê²°ê³¼ ìš”ì•½ í‘œì‹œ
    });

    eventSource.addEventListener('master_complete', (event) => {
        const data = JSON.parse(event.data);
        console.log('ìµœì¢… ë‹µë³€:', data.message);
        // UI: ìµœì¢… ë‹µë³€ í‘œì‹œ
    });

    eventSource.addEventListener('done', (event) => {
        eventSource.close();
    });
    ```

    **Frontend UI ì˜ˆì‹œ:**
    ```
    [Master Agent]
    â”œâ”€ ğŸ“Š Research Agent âœ…
    â”‚   â”œâ”€ planner âœ…
    â”‚   â”œâ”€ data_worker âœ…
    â”‚   â”œâ”€ bull_worker âœ…
    â”‚   â”œâ”€ bear_worker âœ…
    â”‚   â”œâ”€ insight_worker âœ…
    â”‚   â””â”€ synthesis âœ…
    â”‚   ê²°ê³¼: SELL, ëª©í‘œê°€ 90,000ì›
    â”‚
    â”œâ”€ ğŸ¯ Strategy Agent âœ…
    â”‚   â””â”€ ì „ëµ: MOMENTUM
    â”‚
    â””â”€ âš ï¸ Risk Agent âœ…
        â””â”€ ë¦¬ìŠ¤í¬: MEDIUM

    ìµœì¢… ë‹µë³€: í˜„ì¬ ì‚¼ì„±ì „ìëŠ” SELL ì¶”ì²œì…ë‹ˆë‹¤...
    ```
    """
    user_id = request.user_id or str(uuid.uuid4())
    conversation_id = request.conversation_id or str(uuid.uuid4())

    return StreamingResponse(
        stream_multi_agent_execution(
            message=request.message,
            user_id=user_id,
            conversation_id=conversation_id,
            automation_level=request.automation_level,
            stream_thinking=request.stream_thinking
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/sessions")
async def get_chat_sessions(
    limit: int = 20,
    offset: int = 0,
):
    """
    ëŒ€í™” ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ

    Args:
        limit: ì¡°íšŒí•  ì„¸ì…˜ ìˆ˜ (ê¸°ë³¸ê°’: 20)
        offset: ê±´ë„ˆë›¸ ì„¸ì…˜ ìˆ˜ (ê¸°ë³¸ê°’: 0)

    Returns:
        {
            "sessions": [
                {
                    "conversation_id": "uuid",
                    "title": "ì²« ë©”ì‹œì§€ ë‚´ìš©",
                    "last_message": "ë§ˆì§€ë§‰ ë©”ì‹œì§€",
                    "created_at": "2025-01-09T10:00:00",
                    "updated_at": "2025-01-09T10:30:00",
                    "message_count": 10
                }
            ],
            "total": 100,
            "limit": 20,
            "offset": 0
        }
    """
    try:
        # Demo ì‚¬ìš©ì UUID
        demo_user_uuid = settings.demo_user_uuid

        # ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ì „ì²´ ì¡°íšŒ í›„ offset ì ìš©)
        all_sessions = await chat_history_service.list_sessions(
            user_id=demo_user_uuid,
            limit=limit + offset  # offsetë§Œí¼ ë” ê°€ì ¸ì˜´
        )

        # offset ì ìš©í•˜ì—¬ ìŠ¬ë¼ì´ì‹±
        sessions_slice = all_sessions[offset:offset + limit]

        # API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        formatted_sessions = []
        for session_data in sessions_slice:
            first_msg = session_data.get("first_user_message")
            last_msg = session_data.get("last_message")
            chat_session = session_data.get("session")

            formatted_sessions.append({
                "conversation_id": str(session_data["conversation_id"]),
                "title": first_msg.content[:50] if first_msg and first_msg.content else "ìƒˆ ëŒ€í™”",
                "last_message": last_msg.content[:100] if last_msg and last_msg.content else "",
                "created_at": chat_session.created_at.isoformat() if chat_session and hasattr(chat_session, "created_at") else None,
                "updated_at": chat_session.last_message_at.isoformat() if chat_session and hasattr(chat_session, "last_message_at") and chat_session.last_message_at else None,
                "message_count": session_data.get("message_count", 0)
            })

        return {
            "sessions": formatted_sessions,
            "total": len(all_sessions),
            "limit": limit,
            "offset": offset
        }

    except Exception as e:
        logger.error(f"âŒ [ChatSessions] ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {
            "sessions": [],
            "total": 0,
            "limit": limit,
            "offset": offset
        }


@router.get("/sessions/{conversation_id}")
async def get_chat_session(conversation_id: str):
    """
    íŠ¹ì • ëŒ€í™” ì„¸ì…˜ì˜ ë©”ì‹œì§€ ì¡°íšŒ

    Args:
        conversation_id: ëŒ€í™” ID (UUID)

    Returns:
        {
            "conversation_id": "uuid",
            "messages": [
                {
                    "role": "user",
                    "content": "ì•ˆë…•í•˜ì„¸ìš”",
                    "created_at": "2025-01-09T10:00:00"
                },
                {
                    "role": "assistant",
                    "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                    "created_at": "2025-01-09T10:00:05"
                }
            ]
        }
    """
    try:
        conversation_uuid = uuid.UUID(conversation_id)
        history = await chat_history_service.get_history(
            conversation_id=conversation_uuid,
            limit=100  # ìµœê·¼ 100ê°œ ë©”ì‹œì§€
        )

        if not history:
            return {
                "conversation_id": conversation_id,
                "messages": []
            }

        # ë©”ì‹œì§€ í¬ë§·íŒ…
        messages = []
        for msg in history.get("messages", []):
            messages.append({
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at.isoformat() if hasattr(msg, "created_at") else None
            })

        return {
            "conversation_id": conversation_id,
            "messages": messages
        }

    except ValueError:
        logger.error(f"âŒ [ChatSession] ì˜ëª»ëœ UUID í˜•ì‹: {conversation_id}")
        return {
            "conversation_id": conversation_id,
            "messages": [],
            "error": "Invalid conversation ID format"
        }
    except Exception as e:
        logger.error(f"âŒ [ChatSession] ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "conversation_id": conversation_id,
            "messages": [],
            "error": str(e)
        }


@router.delete("/sessions/{conversation_id}")
async def delete_chat_session(conversation_id: str):
    """
    ëŒ€í™” ì„¸ì…˜ ì‚­ì œ

    Args:
        conversation_id: ëŒ€í™” ID (UUID)

    Returns:
        {
            "success": true,
            "conversation_id": "uuid",
            "message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    """
    try:
        conversation_uuid = uuid.UUID(conversation_id)

        # ì„¸ì…˜ ì‚­ì œ (delete_history ì‚¬ìš©)
        await chat_history_service.delete_history(conversation_id=conversation_uuid)

        return {
            "success": True,
            "conversation_id": conversation_id,
            "message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except ValueError:
        logger.error(f"âŒ [DeleteSession] ì˜ëª»ëœ UUID í˜•ì‹: {conversation_id}")
        return {
            "success": False,
            "conversation_id": conversation_id,
            "error": "Invalid conversation ID format"
        }
    except Exception as e:
        logger.error(f"âŒ [DeleteSession] ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "conversation_id": conversation_id,
            "error": str(e)
        }
