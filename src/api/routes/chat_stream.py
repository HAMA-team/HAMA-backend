"""
ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° API (Server-Sent Events)

ì‹¤ì‹œê°„ìœ¼ë¡œ AI ì‚¬ê³  ê³¼ì •ê³¼ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°
"""
import json
import logging
import uuid
from typing import Optional, AsyncGenerator

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from src.agents.research.react_agent import create_research_agent
from src.agents.thinking_trace import collect_thinking_trace
from src.agents.aggregator import personalize_response
from src.agents.router import route_query
from src.services.user_profile_service import user_profile_service
from src.models.database import get_db_context

logger = logging.getLogger(__name__)

router = APIRouter()


class ChatStreamRequest(BaseModel):
    """ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­"""
    message: str
    user_id: Optional[str] = None
    conversation_id: Optional[str] = None
    automation_level: int = Field(default=2, ge=1, le=3)


async def generate_chat_stream(
    message: str,
    user_id: str,
    conversation_id: str,
    automation_level: int
) -> AsyncGenerator[str, None]:
    """
    ì±„íŒ… ì‘ë‹µì„ SSE í˜•ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°

    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        user_id: ì‚¬ìš©ì ID
        conversation_id: ëŒ€í™” ID
        automation_level: ìë™í™” ë ˆë²¨

    Yields:
        SSE í˜•ì‹ ë¬¸ìì—´
            event: thought | tool_call | tool_result | answer | error | done
            data: JSON í˜ì´ë¡œë“œ
    """
    logger.info(f"ğŸ“¡ [ChatStream] ì‹œì‘: {message[:50]}...")

    try:
        # 1. ì‚¬ìš©ì í”„ë¡œíŒŒì¼ ë¡œë“œ
        async with get_db_context() as db:
            user_profile = await user_profile_service.get_user_profile(user_id, db)

        yield f"event: user_profile\ndata: {json.dumps({'profile': user_profile})}\n\n"

        # 2. Router íŒë‹¨
        routing_decision = await route_query(
            query=message,
            user_profile=user_profile,
            conversation_history=[]
        )

        yield f"event: routing\ndata: {json.dumps(routing_decision.dict())}\n\n"

        # 3. Agent ìƒì„±
        agent = create_research_agent(
            depth_level=routing_decision.depth_level,
            user_profile=user_profile
        )

        # 4. ì…ë ¥ êµ¬ì„±
        from langchain_core.messages import HumanMessage

        input_state = {
            "messages": [HumanMessage(content=message)]
        }

        config = {
            "configurable": {
                "thread_id": conversation_id,
                "user_id": user_id
            }
        }

        # 5. Thinking Trace ìŠ¤íŠ¸ë¦¬ë°
        agent_result = None

        async for event in collect_thinking_trace(agent, input_state, config):
            event_type = event.get("type")
            content = event.get("content")

            # SSE í˜•ì‹ìœ¼ë¡œ ì „ì†¡
            if event_type == "thought":
                yield f"event: thought\ndata: {json.dumps({'content': content})}\n\n"

            elif event_type == "tool_call":
                yield f"event: tool_call\ndata: {json.dumps(content)}\n\n"

            elif event_type == "tool_result":
                yield f"event: tool_result\ndata: {json.dumps(content)}\n\n"

            elif event_type == "answer":
                # ìµœì¢… ë‹µë³€ (ì•„ì§ ê°œì¸í™” ì „)
                agent_result = content

            elif event_type == "error":
                yield f"event: error\ndata: {json.dumps({'error': content})}\n\n"

        # 6. ë‹µë³€ ê°œì¸í™”
        if agent_result:
            personalized = await personalize_response(
                agent_results={"research": agent_result},
                user_profile=user_profile,
                routing_decision=routing_decision.dict()
            )

            final_response = personalized.get("response")

            yield f"event: answer\ndata: {json.dumps({'content': final_response})}\n\n"

        # 7. ì™„ë£Œ
        yield f"event: done\ndata: {json.dumps({'conversation_id': conversation_id})}\n\n"

        logger.info("âœ… [ChatStream] ì™„ë£Œ")

    except Exception as e:
        logger.error(f"âŒ [ChatStream] ì—ëŸ¬: {e}")
        yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"


@router.post("/stream")
async def chat_stream(request: ChatStreamRequest):
    """
    ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° API

    ì‹¤ì‹œê°„ìœ¼ë¡œ AI ì‚¬ê³  ê³¼ì •ê³¼ ë‹µë³€ì„ ì „ì†¡í•©ë‹ˆë‹¤.

    **ì‘ë‹µ í˜•ì‹: Server-Sent Events (SSE)**

    **ì´ë²¤íŠ¸ íƒ€ì…:**
    - `user_profile`: ì‚¬ìš©ì í”„ë¡œíŒŒì¼ ë¡œë“œ ì™„ë£Œ
    - `routing`: Router íŒë‹¨ ì™„ë£Œ
    - `thought`: LLM ì‚¬ê³  ê³¼ì •
    - `tool_call`: ë„êµ¬ í˜¸ì¶œ ì‹œì‘
    - `tool_result`: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
    - `answer`: ìµœì¢… ë‹µë³€ (ê°œì¸í™” ì™„ë£Œ)
    - `error`: ì—ëŸ¬ ë°œìƒ
    - `done`: ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ

    **Frontend ì‚¬ìš© ì˜ˆì‹œ (JavaScript):**
    ```javascript
    const eventSource = new EventSource('/api/chat/stream');

    eventSource.addEventListener('thought', (event) => {
        const data = JSON.parse(event.data);
        console.log('Thinking:', data.content);
    });

    eventSource.addEventListener('tool_call', (event) => {
        const data = JSON.parse(event.data);
        console.log('Tool Call:', data.tool, data.input);
    });

    eventSource.addEventListener('answer', (event) => {
        const data = JSON.parse(event.data);
        console.log('Answer:', data.content);
    });

    eventSource.addEventListener('done', (event) => {
        eventSource.close();
    });
    ```
    """
    user_id = request.user_id or str(uuid.uuid4())
    conversation_id = request.conversation_id or str(uuid.uuid4())

    return StreamingResponse(
        generate_chat_stream(
            message=request.message,
            user_id=user_id,
            conversation_id=conversation_id,
            automation_level=request.automation_level
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )
