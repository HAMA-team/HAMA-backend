"""
AI í”„ë¡œíŒŒì¼ ìƒì„± ì„œë¹„ìŠ¤

ìŠ¤í¬ë¦¬ë‹ ì‘ë‹µ + í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ìœ¼ë¡œ ì‚¬ìš©ì íˆ¬ì ì„±í–¥ í”„ë¡œíŒŒì¼ ìë™ ìƒì„±
"""
import json
import logging
from typing import Optional, List, Dict, Any

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from src.config.settings import settings

logger = logging.getLogger(__name__)


class GeneratedProfile(BaseModel):
    """AI ìƒì„± í”„ë¡œíŒŒì¼ ìŠ¤í‚¤ë§ˆ"""
    expertise_level: str  # beginner | intermediate | expert
    investment_style: str  # conservative | moderate | aggressive
    risk_tolerance: str  # low | medium | high
    preferred_sectors: List[str]
    trading_style: str  # short_term | long_term
    portfolio_concentration: float  # 0.0-1.0
    technical_level: str  # basic | intermediate | advanced
    preferred_depth: str  # brief | detailed | comprehensive
    wants_explanations: bool
    wants_analogies: bool
    llm_generated_profile: str  # ìì—°ì–´ í”„ë¡œíŒŒì¼ (200ì ì´ë‚´)


def analyze_portfolio_pattern(portfolio_data: List[Dict[str, Any]]) -> str:
    """
    í¬íŠ¸í´ë¦¬ì˜¤ íŒ¨í„´ ë¶„ì„

    Args:
        portfolio_data: ë³´ìœ  ì¢…ëª© ë¦¬ìŠ¤íŠ¸
            ì˜ˆ: [{"stock_code": "005930", "quantity": 10, "avg_price": 70000}]

    Returns:
        ìì—°ì–´ ë¶„ì„ ê²°ê³¼
    """
    if not portfolio_data:
        return "(í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì—†ìŒ)"

    # 1. ì¢…ëª© ìˆ˜
    stock_count = len(portfolio_data)

    # 2. ì§‘ì¤‘ë„ ê³„ì‚° (HHI - Herfindahl-Hirschman Index)
    total_value = sum(item["quantity"] * item["avg_price"] for item in portfolio_data)

    if total_value == 0:
        concentration = 0.0
    else:
        hhi = sum(
            ((item["quantity"] * item["avg_price"]) / total_value) ** 2
            for item in portfolio_data
        )
        concentration = hhi

    # 3. ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
    concentration_desc = "ì§‘ì¤‘ íˆ¬ì" if concentration > 0.5 else "ë¶„ì‚° íˆ¬ì"

    analysis = f"""
í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„:
- ì¢…ëª© ìˆ˜: {stock_count}ê°œ
- ì§‘ì¤‘ë„: {concentration:.2f} (0=ì™„ì „ë¶„ì‚°, 1=ì™„ì „ì§‘ì¤‘)
- íˆ¬ì íŒ¨í„´: {concentration_desc}
- ì´ íˆ¬ìì•¡: {total_value:,.0f}ì›
"""

    return analysis.strip()


async def generate_ai_profile(
    screening_answers: Dict[str, Any],
    portfolio_data: Optional[List[Dict[str, Any]]] = None,
    config: Optional[RunnableConfig] = None,
) -> Dict[str, Any]:
    """
    ìŠ¤í¬ë¦¬ë‹ ì‘ë‹µ + í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ LLMìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í”„ë¡œíŒŒì¼ ìƒì„±

    Args:
        screening_answers: ì˜¨ë³´ë”© ì„¤ë¬¸ ì‘ë‹µ
            ì˜ˆ: {
                "investment_goal": "long_term_growth",
                "investment_period": "3_years_plus",
                "risk_questions": [...],
                "preferred_sectors": ["ë°˜ë„ì²´", "ë°°í„°ë¦¬"],
                "expected_trade_frequency": "ì£¼ 1íšŒ"
            }
        portfolio_data: ê¸°ì¡´ í¬íŠ¸í´ë¦¬ì˜¤ (ì„ íƒì )

    Returns:
        ìƒì„±ëœ í”„ë¡œíŒŒì¼ (dict)
    """
    logger.info("ğŸ¤– [ProfileGenerator] AI í”„ë¡œíŒŒì¼ ìƒì„± ì‹œì‘")

    # 1. í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
    portfolio_analysis = ""
    if portfolio_data:
        portfolio_analysis = analyze_portfolio_pattern(portfolio_data)
        logger.info(f"ğŸ“Š [Portfolio Analysis]:\n{portfolio_analysis}")

    # 2. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    profile_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ íˆ¬ìì ì„±í–¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì„ë¬´:**
1. ìŠ¤í¬ë¦¬ë‹ ì‘ë‹µ ë¶„ì„
2. í¬íŠ¸í´ë¦¬ì˜¤ ë³´ìœ  íŒ¨í„´ ë¶„ì„ (ìˆëŠ” ê²½ìš°)
3. íˆ¬ì ì„±í–¥ í”„ë¡œíŒŒì¼ ìƒì„±

**ì¶œë ¥ í˜•ì‹:**
JSONìœ¼ë¡œ ë‹¤ìŒ í•„ë“œë¥¼ ë°˜í™˜í•˜ì„¸ìš”:

- **expertise_level**: "beginner" | "intermediate" | "expert"
  - beginner: íˆ¬ì ê²½í—˜ 1ë…„ ë¯¸ë§Œ, ê¸°ë³¸ ìš©ì–´ ì´í•´ í•„ìš”
  - intermediate: íˆ¬ì ê²½í—˜ 1-3ë…„, ì£¼ìš” ì§€í‘œ ì´í•´
  - expert: íˆ¬ì ê²½í—˜ 3ë…„ ì´ìƒ, DCF/ë°¸ë¥˜ì—ì´ì…˜ ì´í•´

- **investment_style**: "conservative" | "moderate" | "aggressive"
  - conservative: ì•ˆì •ì  ìˆ˜ìµ, ë‚®ì€ ë³€ë™ì„± ì„ í˜¸
  - moderate: ê· í˜•ì¡íŒ ì ‘ê·¼, ì¤‘ê°„ ìœ„í—˜
  - aggressive: ê³ ìœ„í—˜ ê³ ìˆ˜ìµ, ë³€ë™ì„± ìˆ˜ìš©

- **risk_tolerance**: "low" | "medium" | "high"
  - ì†ì‹¤ í—ˆìš© ë²”ìœ„, ë³€ë™ì„± ìˆ˜ìš©ë„ ê¸°ë°˜

- **preferred_sectors**: list[str]
  - ê´€ì‹¬ ì„¹í„° ë¦¬ìŠ¤íŠ¸

- **trading_style**: "short_term" | "long_term"
  - short_term: ë‹¨íƒ€, ìŠ¤ìœ™ (ë§¤ë§¤ ë¹ˆë„ ì£¼ 3íšŒ ì´ìƒ)
  - long_term: ì¥ê¸° ë³´ìœ  (ì›” 1íšŒ ì´í•˜)

- **portfolio_concentration**: 0.0-1.0
  - í¬íŠ¸í´ë¦¬ì˜¤ ì§‘ì¤‘ë„ (0=ì™„ì „ë¶„ì‚°, 1=ì™„ì „ì§‘ì¤‘)
  - í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê³„ì‚°ê°’ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¶”ì •

- **technical_level**: "basic" | "intermediate" | "advanced"
  - basic: PER, PBR ì •ë„ë§Œ ì´í•´
  - intermediate: ROE, ë¶€ì±„ë¹„ìœ¨ ë“± ì£¼ìš” ì§€í‘œ ì´í•´
  - advanced: DCF, WACC, ë¯¼ê°ë„ ë¶„ì„ ì´í•´

- **preferred_depth**: "brief" | "detailed" | "comprehensive"
  - expertise_levelì— ë”°ë¼ ìë™ ì„¤ì •
  - beginner â†’ brief
  - intermediate â†’ detailed
  - expert â†’ comprehensive

- **wants_explanations**: bool
  - beginner â†’ true (ìš©ì–´ ì„¤ëª… í•„ìš”)
  - intermediate â†’ false (í•µì‹¬ë§Œ)
  - expert â†’ false

- **wants_analogies**: bool
  - beginner â†’ true (ë¹„ìœ  ì‚¬ìš©)
  - ê·¸ ì™¸ â†’ false

- **llm_generated_profile**: str (200ì ì´ë‚´)
  - ìì—°ì–´ë¡œ ì‚¬ìš©ì íˆ¬ì ì„±í–¥ ìš”ì•½
  - ì˜ˆ: "ì´ íˆ¬ììëŠ” ì¥ê¸° ì„±ì¥ì„ ëª©í‘œë¡œ í•˜ë©°, ë°˜ë„ì²´ì™€ ë°°í„°ë¦¬ ì„¹í„°ì— ì§‘ì¤‘ íˆ¬ìí•˜ëŠ” ê³µê²©ì  ì„±í–¥ì…ë‹ˆë‹¤..."

**ë¶„ì„ ê¸°ì¤€:**
1. investment_goal â†’ investment_style ê²°ì •
2. risk_questions ì‘ë‹µ â†’ risk_tolerance ê²°ì •
3. expected_trade_frequency â†’ trading_style ê²°ì •
4. portfolio_data (ìˆìœ¼ë©´) â†’ portfolio_concentration ê³„ì‚°
5. ì¢…í•© íŒë‹¨ â†’ expertise_level, technical_level ê²°ì •
"""),
        ("human", """**ìŠ¤í¬ë¦¬ë‹ ì‘ë‹µ:**
{screening_answers}

**í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„:**
{portfolio_analysis}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ìì í”„ë¡œíŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”.""")
    ])

    # 3. LLM í˜¸ì¶œ
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.3,
        api_key=settings.OPENAI_API_KEY
    )

    structured_llm = llm.with_structured_output(GeneratedProfile)
    profile_chain = profile_prompt | structured_llm

    try:
        prompt_inputs = {
            "screening_answers": json.dumps(
                screening_answers, ensure_ascii=False, indent=2
            ),
            "portfolio_analysis": portfolio_analysis or "(í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì—†ìŒ)",
        }

        if config is not None:
            result = await profile_chain.ainvoke(prompt_inputs, config=config)
        else:
            result = await profile_chain.ainvoke(prompt_inputs)

        profile_dict = result.dict()

        logger.info(f"âœ… [ProfileGenerator] í”„ë¡œíŒŒì¼ ìƒì„± ì™„ë£Œ")
        logger.info(f"   - expertise_level: {profile_dict['expertise_level']}")
        logger.info(f"   - investment_style: {profile_dict['investment_style']}")
        logger.info(f"   - risk_tolerance: {profile_dict['risk_tolerance']}")
        logger.info(f"   - trading_style: {profile_dict['trading_style']}")

        return profile_dict

    except Exception as e:
        logger.error(f"âŒ [ProfileGenerator] ì—ëŸ¬: {e}")

        # Fallback: ê¸°ë³¸ í”„ë¡œíŒŒì¼
        fallback_profile = {
            "expertise_level": "intermediate",
            "investment_style": "moderate",
            "risk_tolerance": "medium",
            "preferred_sectors": screening_answers.get("preferred_sectors", []),
            "trading_style": "long_term",
            "portfolio_concentration": 0.5,
            "technical_level": "intermediate",
            "preferred_depth": "detailed",
            "wants_explanations": True,
            "wants_analogies": False,
            "llm_generated_profile": f"ê¸°ë³¸ í”„ë¡œíŒŒì¼ (ì—ëŸ¬ ë°œìƒ: {str(e)})"
        }

        logger.warning(f"âš ï¸ [ProfileGenerator] Fallback í”„ë¡œíŒŒì¼ ì‚¬ìš©")
        return fallback_profile
