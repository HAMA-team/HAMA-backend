"""
Langgraph Supervisor íŒ¨í„´ ê¸°ë°˜ ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸

Master Agentì˜ ì—­í•  (ìˆœìˆ˜ ì¡°ìœ¨ì):
1. ì‚¬ìš©ì ì§ˆì˜ë¥¼ LLMìœ¼ë¡œ ë¶„ì„
2. ì ì ˆí•œ ì—ì´ì „íŠ¸ë“¤ ì„ íƒ (LLM ê¸°ë°˜ ë™ì  ë¼ìš°íŒ…)
3. ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë³‘ë ¬ ê°€ëŠ¥)
4. ê²°ê³¼ í†µí•©

ì¤‘ìš”: MasterëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ!
      ëª¨ë“  ì‹¤ì œ ì‘ì—…ì€ ì„œë¸Œê·¸ë˜í”„(ì—ì´ì „íŠ¸)ê°€ ìˆ˜í–‰
      HITLë„ ê° ì„œë¸Œê·¸ë˜í”„ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬
"""
import asyncio
import logging
from functools import lru_cache
from pathlib import Path
from typing import Any, Dict, Optional

from langchain_core.language_models import BaseChatModel
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph_supervisor import create_supervisor

from src.agents.general import general_agent
from src.agents.portfolio import portfolio_agent
from src.agents.research import research_agent
from src.agents.risk import risk_agent
from src.agents.strategy import strategy_agent
from src.agents.trading import trading_agent
from src.config.settings import settings
from src.utils.llm_factory import get_llm

logger = logging.getLogger(__name__)


# ==================== Supervisor êµ¬ì„± ====================

def build_supervisor(automation_level: int = 2, llm: Optional[BaseChatModel] = None):
    """
    Langgraph Supervisor íŒ¨í„´ ê¸°ë°˜ Master Agent ì •ì˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if llm is None:
        llm = get_llm(
            temperature=0,
            max_tokens=settings.MAX_TOKENS,
        )

    supervisor_prompt = f"""ë‹¹ì‹ ì€ íˆ¬ì ì—ì´ì „íŠ¸ íŒ€ì„ ê´€ë¦¬í•˜ëŠ” Supervisorì…ë‹ˆë‹¤.

**ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:**

1. **research_agent** (ì¢…ëª© ë¶„ì„)
   - ê¸°ì—… ì¬ë¬´ ë¶„ì„ (ì¬ë¬´ì œí‘œ, ë¹„ìœ¨)
   - ê¸°ìˆ ì  ë¶„ì„ (ì°¨íŠ¸, ì§€í‘œ)
   - ë‰´ìŠ¤ ê°ì • ë¶„ì„
   - ì¢…í•© í‰ê°€ ë° ë“±ê¸‰ ì‚°ì¶œ

2. **strategy_agent** (íˆ¬ì ì „ëµ)
   - ì‹œì¥ ì‚¬ì´í´ ë¶„ì„
   - ì„¹í„° ë¡œí…Œì´ì…˜ ì „ëµ
   - ìì‚° ë°°ë¶„ ê²°ì •
   - Strategic Blueprint ìƒì„±

3. **risk_agent** (ë¦¬ìŠ¤í¬ í‰ê°€)
   - í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ì¸¡ì • (VaR, ë³€ë™ì„±)
   - ì§‘ì¤‘ë„ ë¦¬ìŠ¤í¬ ë¶„ì„
   - ë¦¬ìŠ¤í¬ ê²½ê³  ë° ê¶Œê³ ì‚¬í•­ ìƒì„±

4. **trading_agent** (ë§¤ë§¤ ì‹¤í–‰)
   - ë§¤ë§¤ ì£¼ë¬¸ ìƒì„± ë° ì‹¤í–‰
   - âš ï¸ automation_level {automation_level}ì—ì„œëŠ” ìŠ¹ì¸ í•„ìš”

5. **portfolio_agent** (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬)
   - í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë° ìµœì í™”
   - ë¦¬ë°¸ëŸ°ì‹± ì œì•ˆ

6. **monitoring_agent** (ì‹œì¥ ëª¨ë‹ˆí„°ë§)
   - ê°€ê²© ë³€ë™ ì¶”ì 
   - ì´ë²¤íŠ¸ ê°ì§€ (ê±°ë˜ëŸ‰ ê¸‰ì¦, VI ë°œë™)
   - ì •ê¸° ë¦¬í¬íŠ¸ ìƒì„±

7. **general_agent** (ì¼ë°˜ ì§ˆì˜ì‘ë‹µ)
   - íˆ¬ì ìš©ì–´ ì„¤ëª… (PER, PBR ë“±)
   - ì¼ë°˜ ì‹œì¥ ì§ˆë¬¸ ì‘ë‹µ
   - íˆ¬ì ì „ëµ êµìœ¡

**ì¤‘ìš” ê·œì¹™:**

1. **ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ë™ì‹œì— í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   ì˜ˆ: ì¢…ëª© ë¶„ì„ ì‹œ research + strategy + risk ë™ì‹œ í˜¸ì¶œ

2. **ì—ì´ì „íŠ¸ ì¡°í•© ì˜ˆì‹œ:**
   - "ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜" â†’ research_agent + strategy_agent + risk_agent
   - "ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±" â†’ portfolio_agent + risk_agent
   - "PERì´ ë­ì•¼?" â†’ general_agent
   - "ì‚¼ì„±ì „ì 10ì£¼ ë§¤ìˆ˜" â†’ trading_agent

3. **HITL (Human-in-the-Loop):**
   - ê° ì—ì´ì „íŠ¸ê°€ ë‚´ë¶€ì ìœ¼ë¡œ HITLì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
   - í˜„ì¬ automation_level: {automation_level}
   - trading_agentëŠ” ë ˆë²¨ 2+ ì—ì„œ ìë™ ìŠ¹ì¸ ìš”ì²­

4. **í•„ìš”í•œ ì—ì´ì „íŠ¸ë§Œ ì„ íƒ:**
   - ë¶ˆí•„ìš”í•œ ì—ì´ì „íŠ¸ëŠ” í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
   - ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³ , ì ì ˆí•œ ì—ì´ì „íŠ¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš”.
"""

    supervisor = create_supervisor(
        agents=[
            research_agent,
            strategy_agent,
            risk_agent,
            trading_agent,
            general_agent,
            portfolio_agent,
            # monitoring_agent,
        ],
        model=llm,
        parallel_tool_calls=True,
        prompt=supervisor_prompt,
    )

    logger.info("âœ… [Supervisor] ìƒì„± ì™„ë£Œ (automation_level=%s)", automation_level)

    return supervisor


def build_state_graph(automation_level: int = 2):
    """
    Supervisor ê¸°ë°˜ Langgraph ì •ì˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ê·¸ë˜í”„ ì •ì˜ ë‹¨ê³„ì—ì„œëŠ” ìˆœìˆ˜í•˜ê²Œ êµ¬ì¡°ë§Œ ìƒì„±í•˜ê³  ë¶€ìˆ˜íš¨ê³¼ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    """
    llm = get_llm(
        temperature=0,
        max_tokens=settings.MAX_TOKENS,
    )
    return build_supervisor(automation_level=automation_level, llm=llm)


def _resolve_backend_key(backend: Optional[str] = None) -> str:
    if backend:
        return backend.lower()
    return getattr(settings, "GRAPH_CHECKPOINT_BACKEND", "memory").lower()


def _create_checkpointer(backend_key: str):
    """
    backend_keyì— ë”°ë¼ ì ì ˆí•œ ì²´í¬í¬ì¸í„° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Note: PostgresSaverëŠ” context managerì´ë¯€ë¡œ __enter__()ë¥¼ í˜¸ì¶œí•˜ì—¬
    ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì–»ìŠµë‹ˆë‹¤. ì—°ê²°ì€ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œê¹Œì§€ ìœ ì§€ë©ë‹ˆë‹¤.
    """
    key = backend_key.lower()

    # PostgreSQL checkpointerëŠ” ë¹„ë™ê¸° context managerë¡œ êµ¬í˜„ë˜ì–´
    # í˜„ì¬ ë™ê¸° ìºì‹± êµ¬ì¡°ì—ì„œëŠ” ì‚¬ìš©ì´ ë³µì¡í•¨
    # í”„ë¡œë•ì…˜ì—ì„œëŠ” Redis checkpointer ì‚¬ìš© ê¶Œì¥
    if key == "postgres":
        logger.warning(
            "PostgreSQL checkpointerëŠ” ë¹„ë™ê¸° ì´ˆê¸°í™”ê°€ í•„ìš”í•˜ì—¬ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "Redis checkpointer ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        )
        return MemorySaver()

    if key == "redis":
        try:
            from langgraph.checkpoint.redis import RedisSaver
        except ImportError as exc:  # pragma: no cover - í™˜ê²½ì— ë”°ë¼ optional dependency
            raise ImportError(
                "langgraph-checkpoint-redis íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            ) from exc

        # Context managerë¥¼ ì—´ì–´ì„œ ì‹¤ì œ RedisSaver ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
        # ì—°ê²°ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ë™ì•ˆ ìœ ì§€ë¨
        conn_manager = RedisSaver.from_conn_string(settings.REDIS_URL)
        return conn_manager.__enter__()

    # ê¸°ë³¸ê°’: ì¸ë©”ëª¨ë¦¬ Saver
    return MemorySaver()


def _loop_token() -> str:
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        return "sync"
    return f"loop-{id(loop)}"


@lru_cache(maxsize=16)
def get_compiled_graph(automation_level: int, backend_key: str, loop_token: str):
    """
    automation_level, backend_key ì¡°í•©ìœ¼ë¡œ ì»´íŒŒì¼ëœ ê·¸ë˜í”„ë¥¼ ìºì‹±í•©ë‹ˆë‹¤.
    """
    state_graph = build_state_graph(automation_level=automation_level)
    checkpointer = _create_checkpointer(backend_key)
    app = state_graph.compile(checkpointer=checkpointer)

    logger.info(
        "ğŸ”§ [Graph] ì»´íŒŒì¼ ì™„ë£Œ (automation_level=%s, backend=%s, loop=%s)",
        automation_level,
        backend_key,
        loop_token,
    )

    return app


# ==================== Main Interface ====================

def build_graph(
    automation_level: int = 2,
    *,
    backend_key: Optional[str] = None,
):
    """
    Backwards compatible helper that mirrors the legacy API expected by
    existing routes. Returns a compiled Langgraph application.
    """
    resolved_backend = _resolve_backend_key(backend_key)
    loop_token = _loop_token()
    return get_compiled_graph(
        automation_level=automation_level,
        backend_key=resolved_backend,
        loop_token=loop_token,
    )


async def run_graph(
    query: str,
    automation_level: int = 2,
    request_id: Optional[str] = None,
    thread_id: Optional[str] = None,
    backend_key: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Langgraph Supervisor ê·¸ë˜í”„ ì‹¤í–‰ í•¨ìˆ˜
    """
    import uuid

    if not request_id:
        request_id = str(uuid.uuid4())

    if not thread_id:
        thread_id = request_id

    resolved_backend = _resolve_backend_key(backend_key)
    loop_token = _loop_token()
    app = get_compiled_graph(
        automation_level=automation_level,
        backend_key=resolved_backend,
        loop_token=loop_token,
    )

    config = {
        "configurable": {
            "thread_id": thread_id,
            "request_id": request_id,
        },
        "recursion_limit": 50,  # Supervisor íŒ¨í„´ì„ ìœ„í•œ recursion_limit ì¦ê°€
    }

    configured_app = app.with_config(config)

    initial_state = {
        "messages": [HumanMessage(content=query)],
        "query": query,
        "request_id": request_id,
    }

    logger.info("ğŸš€ [Graph] ì‹¤í–‰ ì‹œì‘: %s...", query[:50])

    result = await configured_app.ainvoke(initial_state)

    logger.info("âœ… [Graph] ì‹¤í–‰ ì™„ë£Œ (request_id=%s)", request_id)

    final_message = result["messages"][-1]

    return {
        "message": final_message.content
        if hasattr(final_message, "content")
        else str(final_message),
        "messages": result.get("messages", []),
    }
