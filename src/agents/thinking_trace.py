"""
Thinking Trace - AI ì‚¬ê³  ê³¼ì • ì¶”ì 

LangGraphì˜ astream_eventsë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ì˜ ë„êµ¬ í˜¸ì¶œê³¼ ì‚¬ê³  ê³¼ì • ìˆ˜ì§‘
"""
import logging
from typing import AsyncGenerator, Dict, Any, List

logger = logging.getLogger(__name__)


async def collect_thinking_trace(
    agent,
    input_state: Dict[str, Any],
    config: Dict[str, Any]
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì‚¬ê³  ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìˆ˜ì§‘

    Args:
        agent: LangGraph agent (ì„œë¸Œê·¸ë˜í”„ ë˜ëŠ” create_react_agent)
        input_state: ì—ì´ì „íŠ¸ ì…ë ¥ ìƒíƒœ
        config: ì‹¤í–‰ ì„¤ì •

    Yields:
        ì‚¬ê³  ê³¼ì • ì´ë²¤íŠ¸
            - type: "thought" | "tool_call" | "tool_result" | "answer"
            - content: ì´ë²¤íŠ¸ ë‚´ìš©
            - timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
    """
    logger.info("ğŸ§  [ThinkingTrace] ì‚¬ê³  ê³¼ì • ìˆ˜ì§‘ ì‹œì‘")

    try:
        async for event in agent.astream_events(input_state, config, version="v2"):
            event_type = event.get("event")
            event_name = event.get("name", "")
            event_data = event.get("data", {})

            # 1. LLM ì‚¬ê³  ê³¼ì • (on_chat_model_stream)
            if event_type == "on_chat_model_stream":
                chunk = event_data.get("chunk")
                if chunk and hasattr(chunk, "content") and chunk.content:
                    yield {
                        "type": "thought",
                        "content": chunk.content,
                        "metadata": {
                            "model": event_name
                        }
                    }

            # 2. ë„êµ¬ í˜¸ì¶œ ì‹œì‘ (on_tool_start)
            elif event_type == "on_tool_start":
                tool_name = event_name
                tool_input = event_data.get("input", {})

                yield {
                    "type": "tool_call",
                    "content": {
                        "tool": tool_name,
                        "input": tool_input
                    },
                    "metadata": {
                        "run_id": event.get("run_id")
                    }
                }

                logger.info(f"ğŸ”§ [Tool Call] {tool_name}")

            # 3. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ (on_tool_end)
            elif event_type == "on_tool_end":
                tool_name = event_name
                tool_output = event_data.get("output")

                yield {
                    "type": "tool_result",
                    "content": {
                        "tool": tool_name,
                        "output": tool_output
                    },
                    "metadata": {
                        "run_id": event.get("run_id")
                    }
                }

                logger.info(f"âœ… [Tool Result] {tool_name}")

            # 4. ìµœì¢… ë‹µë³€ (on_chain_end with agent name)
            elif event_type == "on_chain_end" and "agent" in event_name.lower():
                final_output = event_data.get("output")

                if final_output:
                    yield {
                        "type": "answer",
                        "content": final_output,
                        "metadata": {
                            "agent": event_name
                        }
                    }

                    logger.info("ğŸ“ [Answer] ìµœì¢… ë‹µë³€ ìƒì„±")

    except Exception as e:
        logger.error(f"âŒ [ThinkingTrace] ì—ëŸ¬: {e}")
        yield {
            "type": "error",
            "content": str(e)
        }


async def collect_thinking_trace_list(
    agent,
    input_state: Dict[str, Any],
    config: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ì‚¬ê³  ê³¼ì •ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘ (non-streaming)

    Args:
        agent: LangGraph agent (ì„œë¸Œê·¸ë˜í”„ ë˜ëŠ” create_react_agent)
        input_state: ì—ì´ì „íŠ¸ ì…ë ¥ ìƒíƒœ
        config: ì‹¤í–‰ ì„¤ì •

    Returns:
        ì‚¬ê³  ê³¼ì • ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    trace_events = []

    async for event in collect_thinking_trace(agent, input_state, config):
        trace_events.append(event)

    logger.info(f"âœ… [ThinkingTrace] ìˆ˜ì§‘ ì™„ë£Œ: {len(trace_events)}ê°œ ì´ë²¤íŠ¸")

    return trace_events


def format_thinking_trace_for_display(trace_events: List[Dict[str, Any]]) -> str:
    """
    ì‚¬ê³  ê³¼ì •ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        trace_events: ì‚¬ê³  ê³¼ì • ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        í¬ë§·íŒ…ëœ Markdown ë¬¸ìì—´
    """
    output_lines = ["## ğŸ§  AI ì‚¬ê³  ê³¼ì •\n"]

    step_number = 1

    for event in trace_events:
        event_type = event.get("type")
        content = event.get("content")

        if event_type == "thought":
            # ì‚¬ê³  ê³¼ì • (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” ëˆ„ì )
            output_lines.append(f"{content}")

        elif event_type == "tool_call":
            # ë„êµ¬ í˜¸ì¶œ
            tool_name = content.get("tool")
            tool_input = content.get("input", {})

            output_lines.append(f"\n**Step {step_number}: {tool_name} í˜¸ì¶œ**\n")
            output_lines.append(f"- ì…ë ¥: `{tool_input}`\n")
            step_number += 1

        elif event_type == "tool_result":
            # ë„êµ¬ ê²°ê³¼
            tool_name = content.get("tool")
            tool_output = content.get("output")

            output_lines.append(f"- ê²°ê³¼: {tool_output}\n")

        elif event_type == "answer":
            # ìµœì¢… ë‹µë³€
            output_lines.append(f"\n---\n\n## ğŸ“ ìµœì¢… ë‹µë³€\n\n{content}\n")

        elif event_type == "error":
            # ì—ëŸ¬
            output_lines.append(f"\nâŒ ì—ëŸ¬: {content}\n")

    return "".join(output_lines)
