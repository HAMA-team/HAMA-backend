"""
Router Agent: ì§ˆë¬¸ ë¶„ì„ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

Routerì˜ ì—­í• :
1. ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„ (simple/moderate/expert)
2. í•„ìš”í•œ ì—ì´ì „íŠ¸ ì„ íƒ (research/strategy/risk/trading/portfolio/general)
3. ë‹µë³€ ê¹Šì´ ìˆ˜ì¤€ ê²°ì • (brief/detailed/comprehensive)
4. ì‚¬ìš©ì í”„ë¡œíŒŒì¼ ê¸°ë°˜ ê°œì¸í™” ì„¤ì •
"""
import logging
from typing import Optional, Any

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel, Field, ConfigDict

from src.config.settings import settings

logger = logging.getLogger(__name__)


class PersonalizationSettings(BaseModel):
    """Routerê°€ ìƒì„±í•˜ëŠ” ê°œì¸í™” ì„¤ì •."""

    model_config = ConfigDict(extra="forbid")

    adjust_for_expertise: Optional[bool] = Field(
        default=None, description="ì‚¬ìš©ì ì „ë¬¸ì„±ì— ë§ì¶° ë‚œì´ë„ë¥¼ ì¡°ì •í• ì§€ ì—¬ë¶€"
    )
    include_explanations: Optional[bool] = Field(
        default=None, description="ì¶”ê°€ ì„¤ëª…ì„ í¬í•¨í• ì§€ ì—¬ë¶€"
    )
    use_analogies: Optional[bool] = Field(
        default=None, description="ë¹„ìœ ë¥¼ í™œìš©í• ì§€ ì—¬ë¶€"
    )
    focus_on_metrics: Optional[list[str]] = Field(
        default=None, description="ê°•ì¡°í•´ì•¼ í•  í•µì‹¬ ì§€í‘œ ë¦¬ìŠ¤íŠ¸"
    )
    sector_comparison: Optional[bool] = Field(
        default=None, description="ë™ì¼ ì„¹í„° ë¹„êµë¥¼ í¬í•¨í• ì§€ ì—¬ë¶€"
    )
    show_formulas: Optional[bool] = Field(
        default=None, description="ê³„ì‚°ì‹ì„ ë…¸ì¶œí• ì§€ ì—¬ë¶€"
    )
    include_sensitivity: Optional[bool] = Field(
        default=None, description="ë¯¼ê°ë„ ë¶„ì„ì„ í¬í•¨í• ì§€ ì—¬ë¶€"
    )
    technical_level: Optional[str] = Field(
        default=None, description="ì„¤ëª…ì„ ì œê³µí•  ê¸°ìˆ ì  ë‚œì´ë„ (basic/intermediate/advanced)"
    )


class RoutingDecision(BaseModel):
    """Routerì˜ íŒë‹¨ ê²°ê³¼"""

    # 1. ì§ˆë¬¸ ë¶„ì„
    query_complexity: str = Field(
        description="ì§ˆë¬¸ ë³µì¡ë„: simple | moderate | expert"
    )
    user_intent: str = Field(
        description="ì‚¬ìš©ì ì˜ë„: quick_info | stock_analysis | trading | portfolio_management | definition | etc"
    )

    # 2. ì¢…ëª© ì •ë³´ ì¶”ì¶œ
    stock_names: Optional[list[str]] = Field(
        default=None,
        description="ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ ì¢…ëª©ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['SKí•˜ì´ë‹‰ìŠ¤', 'ì‚¼ì„±ì „ì']). ì¢…ëª©ì´ ì—†ìœ¼ë©´ None."
    )

    # 3. ì—ì´ì „íŠ¸ ì„ íƒ
    agents_to_call: list[str] = Field(
        description="í˜¸ì¶œí•  ì—ì´ì „íŠ¸ ë¦¬ìŠ¤íŠ¸: research, strategy, risk, trading, portfolio (ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸)"
    )

    # 4. ë‹µë³€ ê¹Šì´ ìˆ˜ì¤€
    depth_level: str = Field(
        description="ë‹µë³€ ê¹Šì´: brief | detailed | comprehensive"
    )

    # 5. ê°œì¸í™” ì„¤ì •
    personalization: PersonalizationSettings = Field(
        description="ê°œì¸í™” ì„¤ì • (adjust_for_expertise, include_explanations, use_analogies ë“±)"
    )

    # 6. ê·¼ê±°
    reasoning: str = Field(description="íŒë‹¨ ê·¼ê±°")

    # 7. ì›Œì»¤ ì§ì ‘ í˜¸ì¶œ (ë‹¨ìˆœ ë°ì´í„° ì¡°íšŒ)
    worker_action: Optional[str] = Field(
        default=None,
        description="ë‹¨ìˆœ ì¡°íšŒ ì›Œì»¤: stock_price | index_price | None. agents_to_callì´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ê³  ë°ì´í„° ì¡°íšŒê°€ í•„ìš”í•œ ê²½ìš°ë§Œ ì‚¬ìš©."
    )
    worker_params: Optional[dict] = Field(
        default=None,
        description="ì›Œì»¤ íŒŒë¼ë¯¸í„° (stock_code, stock_name, index_name ë“±)"
    )

    # 8. ì§ì ‘ ë‹µë³€ (ê°„ë‹¨í•œ ì§ˆë¬¸ì¸ ê²½ìš° Routerê°€ ì§ì ‘ ì‘ë‹µ)
    direct_answer: Optional[str] = Field(
        default=None,
        description="ê°„ë‹¨í•œ ì§ˆë¬¸ì´ë©´ Routerê°€ ì§ì ‘ ìƒì„±í•œ ë‹µë³€. agents_to_callì´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì´ê³  worker_actionë„ Noneì¼ ë•Œë§Œ ì‚¬ìš©."
    )

    def __getitem__(self, item: str) -> Any:
        """dict í˜¸í™˜ì„ ìœ„í•œ í‚¤ ê¸°ë°˜ ì ‘ê·¼ ì§€ì›"""
        if hasattr(self, item):
            return getattr(self, item)
        raise KeyError(item)

    def get(self, item: str, default: Any = None) -> Any:
        """dict.getê³¼ ë™ì¼í•œ ë™ì‘ ì œê³µ"""
        return getattr(self, item, default)

    def keys(self):
        return self.dict().keys()

    def items(self):
        return self.dict().items()

    def values(self):
        return self.dict().values()


async def route_query(
    query: str,
    user_profile: dict,
    conversation_history: Optional[list] = None,
    config: Optional[RunnableConfig] = None,
) -> RoutingDecision:
    """
    Router Agent: ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        user_profile: ì‚¬ìš©ì í”„ë¡œíŒŒì¼ (íˆ¬ì ì„±í–¥, ê²½í—˜ ìˆ˜ì¤€)
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 3í„´)

        config: LangChain RunnableConfig (ì„ íƒì )

    Returns:
        RoutingDecision: ë¼ìš°íŒ… ê²°ì •
    """
    if conversation_history is None:
        conversation_history = []

    # ë¹ˆ ì¿¼ë¦¬ ê²€ì¦
    query = query.strip()
    if not query:
        logger.warning("âš ï¸ [Router] ë¹ˆ ì§ˆë¬¸ ê°ì§€ - Supervisorê°€ ì§ì ‘ ì²˜ë¦¬")
        return RoutingDecision(
            query_complexity="simple",
            user_intent="general_inquiry",
            stock_names=None,
            agents_to_call=[],
            depth_level="brief",
            personalization=PersonalizationSettings(
                adjust_for_expertise=True,
                include_explanations=True,
                use_analogies=True,
                technical_level="basic",
            ),
            reasoning="ë¹ˆ ì§ˆë¬¸ì´ë¯€ë¡œ Supervisorê°€ ì§ì ‘ ì²˜ë¦¬",
        )

    # ì‚¬ìš©ì í”„ë¡œíŒŒì¼ ê¸°ë³¸ê°’
    user_expertise = user_profile.get("expertise_level", "intermediate")
    investment_style = user_profile.get("investment_style", "moderate")
    preferred_sectors = user_profile.get("preferred_sectors", [])
    avg_trades_per_day = user_profile.get("avg_trades_per_day", 1.0)
    technical_level = user_profile.get("technical_level", "intermediate")

    router_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """íˆ¬ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì—ì´ì „íŠ¸ ë˜ëŠ” ì›Œì»¤ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.

**ìš°ì„ ìˆœìœ„ 1: ì›Œì»¤ ì§ì ‘ í˜¸ì¶œ (ë¹ ë¥¸ ë‹¨ìˆœ ì¡°íšŒ)**
agents_to_call = [], worker_action ì„¤ì •:
- "ì‚¼ì„±ì „ì í˜„ì¬ê°€?", "SKí•˜ì´ë‹‰ìŠ¤ ì£¼ê°€?" â†’ worker_action="stock_price", worker_params={{"stock_code": "005930", "stock_name": "ì‚¼ì„±ì „ì"}}
- "ì½”ìŠ¤í”¼ ì§€ìˆ˜?", "ì½”ìŠ¤ë‹¥ ì–¼ë§ˆì•¼?" â†’ worker_action="index_price", worker_params={{"index_name": "ì½”ìŠ¤í”¼"}}

**ìš°ì„ ìˆœìœ„ 2: ì—ì´ì „íŠ¸ í˜¸ì¶œ (ë¶„ì„/ì „ëµ/ì‹¤í–‰)**
- research: ì¢…ëª© ë¶„ì„ ìš”ì²­ ("ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜", "ì¬ë¬´ì œí‘œ ë¶„ì„")
- strategy: íˆ¬ì ì „ëµ/íƒ€ì´ë° ("ì–¸ì œ ì‚¬ì•¼í•´?", "ë§¤ìˆ˜ íƒ€ì´ë°")
- risk: ë¦¬ìŠ¤í¬ í‰ê°€ ("ìœ„í—˜ë„ëŠ”?", "ì†ì‹¤ ê°€ëŠ¥ì„±")
- portfolio: í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ/ê´€ë¦¬ ("ë³´ìœ  í˜„í™©", "ë¦¬ë°¸ëŸ°ì‹±")
- trading: ë§¤ë§¤ ì‹¤í–‰ ("ë§¤ìˆ˜", "ë§¤ë„")

**ìš°ì„ ìˆœìœ„ 3: Router ì§ì ‘ ë‹µë³€**
agents_to_call = [], worker_action = None, direct_answer ìƒì„±:
- ì¼ë°˜ ì§ˆë¬¸/ìš©ì–´ ì •ì˜ ("PERì´ ë­ì•¼?", "ì•ˆë…•?")

**ì¢…ëª©ëª… ì¶”ì¶œ:**
ì§ˆë¬¸ì—ì„œ ê¸°ì—…ëª…ì„ ì¶”ì¶œí•˜ì„¸ìš” (ì˜ˆ: "lg í™”í•™" â†’ ["LGí™”í•™"]).
ì¢…ëª©ì´ ì—†ìœ¼ë©´ None.

**ë³µì¡ë„:**
- simple: ë‹¨ìˆœ ì •ë³´ ì¡°íšŒ (í˜„ì¬ê°€, ì§€ìˆ˜)
- moderate: ë¶„ì„ í•„ìš” (ì¬ë¬´, ê¸°ìˆ ì  ë¶„ì„)
- expert: ì‹¬ì¸µ ë¶„ì„ (ì „ëµ ìˆ˜ë¦½, ë¦¬ìŠ¤í¬ í‰ê°€)

**ì‚¬ìš©ì:** {user_expertise} ìˆ˜ì¤€, {investment_style} ì„±í–¥

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
""",
            ),
            ("human", "ì§ˆë¬¸: {query}"),
        ]
    )

    # Router ì „ìš© LLM ì´ˆê¸°í™” (OpenAI â†’ Anthropic fallback)
    router_provider = settings.ROUTER_MODEL_PROVIDER.lower()

    llm = None
    if router_provider == "openai":
        try:
            # max_completion_tokens: structured output + reasoning tokens ëª¨ë‘ í¬í•¨
            # o1 ëª¨ë¸ì€ reasoning_tokensë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ì¶©ë¶„í•œ ì—¬ìœ  í•„ìš”
            llm = ChatOpenAI(
                model=settings.ROUTER_MODEL,
                temperature=0,
                max_completion_tokens=2500,  # ì¦ê°€: structured output(500) + reasoning(2000)
                api_key=settings.OPENAI_API_KEY,
            )
            logger.info(f"ğŸ¤– [Router] OpenAI ëª¨ë¸ ì‚¬ìš©: {settings.ROUTER_MODEL}")
        except Exception as e:
            logger.warning(f"âš ï¸ [Router] OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨, Anthropicìœ¼ë¡œ fallback: {e}")

    if llm is None:  # OpenAI ì‹¤íŒ¨ ë˜ëŠ” anthropic ì„¤ì •
        try:
            llm = ChatAnthropic(
                model=settings.ROUTER_MODEL or "claude-3-5-sonnet-20241022",
                temperature=0,
                max_tokens=2000,  # structured output ê³ ë ¤
                api_key=settings.ANTHROPIC_API_KEY,
            )
            logger.info(f"ğŸ¤– [Router] Anthropic ëª¨ë¸ ì‚¬ìš©: {settings.ROUTER_MODEL or 'claude-3-5-sonnet-20241022'}")
        except Exception as e:
            logger.error(f"âŒ [Router] Anthropic ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError("Router LLM ì´ˆê¸°í™” ì‹¤íŒ¨ (OpenAI, Anthropic ëª¨ë‘ ì‹¤íŒ¨)")

    structured_llm = llm.with_structured_output(RoutingDecision)
    router_chain = router_prompt | structured_llm

    logger.info(f"ğŸ§­ [Router] ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: {query[:50]}...")

    prompt_inputs = {
        "query": query,
        "user_expertise": user_expertise,
        "investment_style": investment_style,
    }

    try:
        if config is not None:
            result = await router_chain.ainvoke(prompt_inputs, config=config)
        else:
            result = await router_chain.ainvoke(prompt_inputs)

        logger.info(f"âœ… [Router] íŒë‹¨ ì™„ë£Œ:")
        logger.info(f"  - ë³µì¡ë„: {result.query_complexity}")
        logger.info(f"  - ì˜ë„: {result.user_intent}")
        logger.info(f"  - ì¢…ëª©ëª…: {result.stock_names}")
        logger.info(f"  - ì—ì´ì „íŠ¸: {result.agents_to_call}")
        logger.info(f"  - ì›Œì»¤: {result.worker_action} (params: {result.worker_params})")
        logger.info(f"  - ê¹Šì´: {result.depth_level}")
        logger.info(f"  - ê·¼ê±°: {result.reasoning}")

        # ê°„ë‹¨í•œ ì§ˆë¬¸ì´ë©´ Routerê°€ ì§ì ‘ ë‹µë³€ ìƒì„± (ì›Œì»¤ í˜¸ì¶œì´ ì—†ëŠ” ê²½ìš°ë§Œ)
        if not result.agents_to_call and not result.worker_action:
            logger.info("ğŸ’¬ [Router] ê°„ë‹¨í•œ ì§ˆë¬¸ - ì§ì ‘ ë‹µë³€ ìƒì„±")

            # ê°„ë‹¨í•œ ë‹µë³€ìš© LLM (structured output ì—†ìŒ, ë¹ ë¥¸ ëª¨ë¸)
            simple_llm = ChatOpenAI(
                model="gpt-4o-mini",  # ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸
                temperature=0.7,
                max_completion_tokens=500,  # ê°„ë‹¨í•œ ë‹µë³€ìš©
                api_key=settings.OPENAI_API_KEY,
            )

            simple_prompt = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ ì¹œì ˆí•œ íˆ¬ì ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ ì›ì¹™:
- 1-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ì „ë‹¬
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹ˆì–´ë„ ì¹œì ˆí•˜ê²Œ ë‹µë³€
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±"""),
                ("human", "{query}")
            ])

            simple_chain = simple_prompt | simple_llm

            try:
                if config is not None:
                    answer_msg = await simple_chain.ainvoke({"query": query}, config=config)
                else:
                    answer_msg = await simple_chain.ainvoke({"query": query})

                direct_answer = answer_msg.content
                result.direct_answer = direct_answer
                logger.info(f"âœ… [Router] ì§ì ‘ ë‹µë³€: {direct_answer[:100]}...")
            except Exception as e:
                logger.error(f"âŒ [Router] ì§ì ‘ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                result.direct_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        elif result.worker_action:
            logger.info(f"âš¡ [Router] ì›Œì»¤ í˜¸ì¶œ: {result.worker_action}")

        return result

    except Exception as e:
        logger.error(f"âŒ [Router] ì—ëŸ¬: {e}")
        raise
