"""
General Agent ë…¸ë“œ í•¨ìˆ˜ë“¤ (Deep Agent ìŠ¤íƒ€ì¼)
"""
import json
import logging
from copy import deepcopy
from typing import Any, Dict, List, Optional

from langchain_core.messages import AIMessage, HumanMessage

from src.config.settings import settings
from src.services.search_service import web_search_service
from src.utils.llm_factory import get_llm
from src.utils.json_parser import safe_json_parse

from .state import GeneralState

logger = logging.getLogger(__name__)

ALLOWED_WORKERS = {"search", "analysis", "insight"}

DEFAULT_PLAN = {
    "plan_summary": "ê²€ìƒ‰ â†’ ì‚¬ì‹¤ ì •ë¦¬ â†’ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ",
    "tasks": [
        {
            "id": "task_1",
            "worker": "search",
            "description": "ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìµœì‹  ì›¹ ì •ë³´ë¥¼ ìˆ˜ì§‘í•œë‹¤.",
        },
        {
            "id": "task_2",
            "worker": "analysis",
            "description": "ê²€ìƒ‰ ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ê³  í•µì‹¬ ì‚¬ì‹¤ì„ ìš”ì•½í•œë‹¤.",
        },
        {
            "id": "task_3",
            "worker": "insight",
            "description": "ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ì™€ ì¶”ê°€ ì°¸ê³  í¬ì¸íŠ¸ë¥¼ ì •ë¦¬í•œë‹¤.",
        },
    ],
}


def _sanitize_tasks(tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not tasks:
        return deepcopy(DEFAULT_PLAN["tasks"])

    sanitized: List[Dict[str, Any]] = []
    for idx, task in enumerate(tasks, start=1):
        worker_raw = str(task.get("worker", "")).lower()

        if worker_raw not in ALLOWED_WORKERS:
            if "search" in worker_raw or "lookup" in worker_raw:
                worker = "search"
            elif "analysis" in worker_raw or "reason" in worker_raw:
                worker = "analysis"
            else:
                worker = "insight"
        else:
            worker = worker_raw

        sanitized.append(
            {
                "id": task.get("id") or f"task_{idx}",
                "worker": worker,
                "description": task.get("description") or task.get("objective") or "ì¡°ì‚¬ ì‘ì—…",
            }
        )

    workers = {task["worker"] for task in sanitized}
    if not workers.issuperset(ALLOWED_WORKERS):
        return deepcopy(DEFAULT_PLAN["tasks"])

    return sanitized


def _task_complete(
    state: GeneralState,
    task: Optional[Dict[str, Any]],
    summary: str,
    extra: Dict[str, Any],
) -> GeneralState:
    completed = list(state.get("completed_tasks") or [])
    notes = list(state.get("task_notes") or [])

    if task:
        completed.append({**task, "status": "done", "summary": summary})
    if summary:
        notes.append(summary)

    update: GeneralState = {
        "completed_tasks": completed,
        "task_notes": notes,
        "current_task": None,
    }
    update.update(extra)
    return update


async def planner_node(state: GeneralState) -> GeneralState:
    query = (state.get("query") or "").strip()

    llm = get_llm(temperature=0, max_tokens=1200)
    prompt = f"""
ë‹¹ì‹ ì€ íˆ¬ì êµìœ¡ ë° ì‹œì¥ ë™í–¥ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” General Agentì˜ í”Œë˜ë„ˆì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸: {query or 'ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "plan_summary": "í•œ ë¬¸ì¥ ìš”ì•½",
  "tasks": [
    {{"id": "task_1", "worker": "search", "description": "..."}},
    {{"id": "task_2", "worker": "analysis", "description": "..."}},
    {{"id": "task_3", "worker": "insight", "description": "..."}}
  ]
}}
worker ê°’ì€ ë°˜ë“œì‹œ search, analysis, insight ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
"""

    plan = None
    try:
        response = await llm.ainvoke(prompt)
        content = response.content if hasattr(response, "content") else str(response)
        plan = safe_json_parse(content, "General/Planner")
    except Exception as exc:
        logger.warning("âš ï¸ [General/Planner] ê³„íš ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ê³„íš ì‚¬ìš©: %s", exc)

    if not isinstance(plan, dict):
        plan = deepcopy(DEFAULT_PLAN)

    sanitized_tasks = _sanitize_tasks(plan.get("tasks", []))
    plan["tasks"] = sanitized_tasks

    plan_message_lines = [
        "ğŸ—ºï¸ ì¡°ì‚¬ ê³„íšì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤.",
        plan.get("plan_summary") or DEFAULT_PLAN["plan_summary"],
    ]
    for task in sanitized_tasks:
        plan_message_lines.append(f"- ({task['worker']}) {task['description']}")

    plan_message = AIMessage(content="\n".join(plan_message_lines))

    return {
        "plan": plan,
        "pending_tasks": deepcopy(sanitized_tasks),
        "completed_tasks": [],
        "current_task": None,
        "task_notes": [],
        "messages": [plan_message],
    }


def task_router_node(state: GeneralState) -> GeneralState:
    pending = list(state.get("pending_tasks") or [])
    if not pending:
        return {"current_task": None, "pending_tasks": []}

    task = pending.pop(0)
    logger.info("ğŸ§­ [General/Router] ë‹¤ìŒ ì‘ì—…: %s (%s)", task["id"], task["worker"])
    return {
        "current_task": task,
        "pending_tasks": pending,
    }


async def search_worker_node(state: GeneralState) -> GeneralState:
    task = state.get("current_task")
    query = (state.get("query") or "").strip()

    if not query:
        message = AIMessage(content="ì§ˆë¬¸ì´ ë¹„ì–´ ìˆì–´ ì›¹ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return _task_complete(
            state,
            task,
            "ê²€ìƒ‰ ìŠ¤í‚µ (ë¹ˆ ì§ˆë¬¸)",
            {"search_results": [], "messages": [message]},
        )

    logger.info("ğŸŒ [General/Search] ì›¹ ê²€ìƒ‰ ì‹¤í–‰: %s", query)
    results = await web_search_service.search(query)

    if results:
        preview_lines = [f"- {item['title']} ({item['url']})" for item in results[:3]]
        summary = f"ì›¹ ê²€ìƒ‰ {len(results)}ê±´ í™•ë³´"
        message = AIMessage(
            content="ì›¹ ê²€ìƒ‰ ê²°ê³¼:\n" + "\n".join(preview_lines)
        )
    else:
        summary = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        message = AIMessage(
            content="ì›¹ ê²€ìƒ‰ì—ì„œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚´ë¶€ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤."
        )

    return _task_complete(
        state,
        task,
        summary,
        {
            "search_results": results,
            "messages": [message],
        },
    )


async def analysis_worker_node(state: GeneralState) -> GeneralState:
    if state.get("error"):
        return state

    task = state.get("current_task")
    query = (state.get("query") or "").strip()
    results = state.get("search_results") or []

    llm = get_llm(temperature=0.2, max_tokens=1500)
    prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•´ í•µì‹¬ ì‚¬ì‹¤ì„ ì •ë¦¬í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}
ê²€ìƒ‰ ê²°ê³¼:
{json.dumps(results[:6], ensure_ascii=False, indent=2)}

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "key_points": ["í•µì‹¬ ì‚¬ì‹¤ 3~5ê°œ"],
  "definitions": ["ê´€ë ¨ ìš©ì–´ ì„¤ëª…"],
  "data_points": ["ìˆ«ì/í†µê³„ ì •ë³´"],
  "caveats": ["ì£¼ì˜í•  ì "]
}}
"""

    try:
        response = await llm.ainvoke(prompt)
        analysis = safe_json_parse(response.content, "General/Analysis")
        if not isinstance(analysis, dict):
            analysis = {}
    except Exception as exc:
        logger.error("âŒ [General/Analysis] LLM ë¶„ì„ ì‹¤íŒ¨: %s", exc)
        return {
            "error": str(exc),
            "current_task": None,
            "messages": [AIMessage(content=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")],
        }

    summary = "ê²€ìƒ‰ ê¸°ë°˜ í•µì‹¬ ì‚¬ì‹¤ ì •ë¦¬"
    preview = ", ".join((analysis.get("key_points") or [])[:2])
    message = AIMessage(
        content="í•µì‹¬ ì‚¬ì‹¤ ìš”ì•½:\n" + (preview or "ê²€ìƒ‰ ê¸°ë°˜ í•µì‹¬ ì‚¬ì‹¤ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    )

    return _task_complete(
        state,
        task,
        summary,
        {
            "analysis": analysis,
            "messages": [message],
        },
    )


async def insight_worker_node(state: GeneralState) -> GeneralState:
    if state.get("error"):
        return state

    task = state.get("current_task")
    query = (state.get("query") or "").strip()
    analysis = state.get("analysis") or {}

    llm = get_llm(temperature=0.3, max_tokens=1200)
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë¶„ì„ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì¸ì‚¬ì´íŠ¸ì™€ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”.

ì§ˆë¬¸: {query}
í•µì‹¬ ë¶„ì„:
{json.dumps(analysis, ensure_ascii=False, indent=2)}

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "insights": ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2~3ê°œ"],
  "follow_up_questions": ["ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•  ì¶”ê°€ ì§ˆë¬¸"]
}}
"""

    try:
        response = await llm.ainvoke(prompt)
        insight = safe_json_parse(response.content, "General/Insight")
        if not isinstance(insight, dict):
            insight = {}
    except Exception as exc:
        logger.error("âŒ [General/Insight] LLM ì‹¤íŒ¨: %s", exc)
        return {
            "error": str(exc),
            "current_task": None,
            "messages": [AIMessage(content=f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {exc}")],
        }

    summary = "ì¸ì‚¬ì´íŠ¸ ë° í›„ì† ì§ˆë¬¸ ì •ë¦¬"
    insight_lines = insight.get("insights") or []
    message = AIMessage(
        content="ì¶”ê°€ ì¸ì‚¬ì´íŠ¸:\n" + "\n".join(f"- {line}" for line in insight_lines[:3])
    )

    return _task_complete(
        state,
        task,
        summary,
        {
            "insight_summary": insight,
            "messages": [message],
        },
    )


async def synthesis_node(state: GeneralState) -> GeneralState:
    if state.get("error"):
        return state

    logger.info("ğŸ§© [General/Synthesis] ìµœì¢… ë‹µë³€ ìƒì„±")

    query = (state.get("query") or "").strip()
    results = state.get("search_results") or []
    analysis = state.get("analysis") or {}
    insight = state.get("insight_summary") or {}

    llm = get_llm(temperature=0.2, max_tokens=1600)
    prompt = f"""ë‹¹ì‹ ì€ íˆ¬ì êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ìë£Œë¥¼ í† ëŒ€ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ê²€ìƒ‰ ê²°ê³¼:
{json.dumps(results[:5], ensure_ascii=False, indent=2)}

í•µì‹¬ ë¶„ì„:
{json.dumps(analysis, ensure_ascii=False, indent=2)}

ì¶”ê°€ ì¸ì‚¬ì´íŠ¸:
{json.dumps(insight, ensure_ascii=False, indent=2)}

ë‹µë³€ ê°€ì´ë“œ:
- ê°œë…ì€ ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–»ì€ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì‚¬ì‹¤ì„ í¬í•¨í•˜ì„¸ìš”.
- ì°¸ê³ í•œ ìë£ŒëŠ” ë²ˆí˜¸ë¡œ í‘œê¸°í•˜ì§€ ë§ê³  ë¬¸ì¥ ì•ˆì—ì„œ ì¶œì²˜ ì´ë¦„ì´ë‚˜ ë§í¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.
- ë§ˆì§€ë§‰ì—ëŠ” 1-2ê°œì˜ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”.
"""

    try:
        response = await llm.ainvoke(prompt)
        answer = response.content if hasattr(response, "content") else str(response)
    except Exception as exc:
        logger.error("âŒ [General/Synthesis] ìµœì¢… ë‹µë³€ ì‹¤íŒ¨: %s", exc)
        return {
            "error": str(exc),
            "messages": [AIMessage(content=f"ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {exc}")],
        }

    top_sources: List[Dict[str, Any]] = []
    for item in results[:3]:
        top_sources.append(
            {
                "title": item.get("title"),
                "url": item.get("url"),
                "snippet": item.get("snippet"),
            }
        )

    message = AIMessage(content=answer)

    completed = list(state.get("completed_tasks") or [])
    completed.append(
        {
            "id": "synthesis",
            "worker": "synthesis",
            "description": "ìµœì¢… ë‹µë³€ ìƒì„±",
            "status": "done",
            "summary": "ì‚¬ìš©ì ì‘ë‹µ ì‘ì„±",
        }
    )

    return {
        "answer": answer,
        "sources": top_sources,
        "messages": [message],
        "completed_tasks": completed,
        "task_notes": list(state.get("task_notes") or []) + ["ìµœì¢… ë‹µë³€ ì‘ì„±"],
        "agent_results": {
            "general": {
                "answer": answer,
                "sources": top_sources,
            }
        },
    }
