"""
General Agent ë…¸ë“œ í•¨ìˆ˜ë“¤

ì¼ë°˜ ì§ˆì˜ì‘ë‹µì„ ìœ„í•œ ë…¸ë“œ
"""
import logging
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from src.agents.general.state import GeneralState

logger = logging.getLogger(__name__)


async def answer_question_node(state: GeneralState) -> dict:
    """
    ì¼ë°˜ ì§ˆë¬¸ ì‘ë‹µ ë…¸ë“œ (LLM)

    íˆ¬ì ìš©ì–´, ê°œë…, ì¼ë°˜ ì‹œì¥ ì§ˆë¬¸ì— ë‹µë³€

    TODO Phase 2:
    - RAG ì—°ë™ (íˆ¬ì ìš©ì–´ ì‚¬ì „)
    - ë²¡í„° DB ê²€ìƒ‰ (ìœ ì‚¬ ì§ˆë¬¸)
    """
    query = state.get("query", "")

    logger.info(f"ğŸ’¬ [General] ì§ˆë¬¸ ì‘ë‹µ ì¤‘: {query[:50]}...")

    try:
        # LLM ì´ˆê¸°í™” (API í‚¤ í™•ì¸)
        from src.config.settings import settings
        if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "test-key-not-used":
            raise ValueError("OPENAI_API_KEY not configured")

        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ íˆ¬ì êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- íˆ¬ì ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…
- ì‹œì¥ ê°œë…ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬
- íˆ¬ì ì „ëµì„ êµìœ¡
- ì¼ë°˜ì ì¸ ì‹œì¥ ì§ˆë¬¸ì— ë‹µë³€

ì¤‘ìš”:
- ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
- ì „ë¬¸ ìš©ì–´ëŠ” í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
- ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”.
- íˆ¬ì ê¶Œìœ ëŠ” í•˜ì§€ ë§ˆì„¸ìš”.

ì˜ˆì‹œ:
Q: PERì´ ë­ì•¼?
A: PER(ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)ì€ ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµ(EPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤.
   ì˜ˆë¥¼ ë“¤ì–´, ì£¼ê°€ê°€ 10,000ì›ì´ê³  EPSê°€ 1,000ì›ì´ë©´ PERì€ 10ë°°ì…ë‹ˆë‹¤.
   ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€, ë†’ì„ìˆ˜ë¡ ê³ í‰ê°€ë¡œ ë³¼ ìˆ˜ ìˆì§€ë§Œ, ì—…ì¢…ë§ˆë‹¤ ì ì • ìˆ˜ì¤€ì´ ë‹¤ë¦…ë‹ˆë‹¤.
"""

        # LLM í˜¸ì¶œ
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=query),
        ]

        response = await llm.ainvoke(messages)

        answer = response.content

        logger.info(f"âœ… [General] ì‘ë‹µ ì™„ë£Œ")

        # Supervisor í˜¸í™˜ì„±ì„ ìœ„í•´ messages í¬í•¨
        messages = list(state.get("messages", []))
        messages.append(AIMessage(content=answer))

        return {
            "answer": answer,
            "sources": [],  # TODO: RAG ì—°ë™ ì‹œ ì¶”ê°€
            "messages": messages,
        }

    except Exception as e:
        logger.warning(f"âš ï¸ [General] LLM í˜¸ì¶œ ì‹¤íŒ¨ (mock ì‘ë‹µ ì‚¬ìš©): {e}")

        # Mock ì‘ë‹µ ìƒì„±
        mock_answers = {
            "per": "PER(ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)ì€ ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµ(EPS)ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€ëœ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "pbr": "PBR(ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨)ì€ ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœìì‚°(BPS)ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. 1 ë¯¸ë§Œì´ë©´ ìˆœìì‚° ëŒ€ë¹„ ì €í‰ê°€ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "default": f"'{query}' ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. (í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œëŠ” mock ì‘ë‹µì´ ì œê³µë©ë‹ˆë‹¤)"
        }

        # í‚¤ì›Œë“œ ê¸°ë°˜ mock ì‘ë‹µ ì„ íƒ
        answer = mock_answers.get("default")
        for keyword, response in mock_answers.items():
            if keyword in query.lower():
                answer = response
                break

        # Mock ì‘ë‹µì„ messagesì— í¬í•¨
        messages = list(state.get("messages", []))
        messages.append(AIMessage(content=answer))

        return {
            "answer": answer,
            "sources": [],
            "messages": messages,
        }
