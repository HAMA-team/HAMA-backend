"""
ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸ ë…¸ë“œ í•¨ìˆ˜ë“¤ (LLM ê¸°ë°˜)

GPT-5 nanoë¥¼ í™œìš©í•œ Intent ë¶„ì„ ë° Supervisor ë…¸ë“œ
"""
from typing import List
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import logging

from src.config.settings import settings
from src.schemas.graph_state import GraphState

logger = logging.getLogger(__name__)


# ==================== Pydantic ëª¨ë¸ ====================

class IntentAnalysis(BaseModel):
    """Intent ë¶„ì„ ê²°ê³¼"""
    intent: str = Field(description="ë¶„ì„ëœ ì‚¬ìš©ì ì˜ë„ (stock_analysis, trade_execution, portfolio_evaluation, rebalancing, performance_check, market_status, general_question ì¤‘ í•˜ë‚˜)")
    stock_code: str | None = Field(default=None, description="ì¢…ëª© ì½”ë“œ (ìˆëŠ” ê²½ìš°)")
    stock_name: str | None = Field(default=None, description="ì¢…ëª© ì´ë¦„ (ìˆëŠ” ê²½ìš°)")
    confidence: float = Field(description="ë¶„ì„ ì‹ ë¢°ë„ (0.0-1.0)")


class AgentSelection(BaseModel):
    """ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼"""
    agents: List[str] = Field(description="í˜¸ì¶œí•  ì—ì´ì „íŠ¸ ID ë¦¬ìŠ¤íŠ¸ (research_agent, strategy_agent, risk_agent, portfolio_agent, monitoring_agent, education_agent ì¤‘ ì„ íƒ)")
    reasoning: str = Field(description="ì—ì´ì „íŠ¸ ì„ íƒ ì´ìœ ")


# ==================== LLM ê¸°ë°˜ Intent ë¶„ì„ ë…¸ë“œ ====================

async def llm_intent_analysis_node(state: GraphState) -> GraphState:
    """
    GPT-5 nano ê¸°ë°˜ ì˜ë„ ë¶„ì„ ë…¸ë“œ

    LangGraph í‘œì¤€: messagesì—ì„œ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    Structured Outputìœ¼ë¡œ intent, ì¢…ëª© ì •ë³´, ì‹ ë¢°ë„ ì¶”ì¶œ
    """
    # messagesì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ
    last_message = state["messages"][-1]
    query = last_message.content if hasattr(last_message, 'content') else str(last_message)

    # Claude LLM ì´ˆê¸°í™”
    from langchain_anthropic import ChatAnthropic
    import os

    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        logger.error(f"âŒ [LLM Intent] ANTHROPIC_API_KEY not found, fallback to keyword analysis")
        # Fallback: í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ì„
        query_lower = query.lower()
        if any(word in query_lower for word in ["ë¦¬ë°¸ëŸ°ì‹±", "ì¬êµ¬ì„±", "ì¬ë°°ë¶„", "ì¡°ì •", "ë¹„ì¤‘"]):
            intent = "rebalancing"
        elif any(word in query_lower for word in ["ë§¤ìˆ˜", "ë§¤ë„", "ì‚¬", "íŒ”"]):
            intent = "trade_execution"
        elif any(word in query_lower for word in ["ìˆ˜ìµë¥ ", "í˜„í™©"]):
            intent = "performance_check"
        elif any(word in query_lower for word in ["í¬íŠ¸í´ë¦¬ì˜¤", "ìì‚°ë°°ë¶„"]):
            intent = "portfolio_evaluation"
        elif any(word in query_lower for word in ["ë¶„ì„", "ì–´ë•Œ", "í‰ê°€", "íˆ¬ì", "ì „ëµ"]):
            intent = "stock_analysis"
        elif "ì‹œì¥" in query_lower:
            intent = "market_status"
        else:
            intent = "general_question"

        logger.info(f"ğŸ” [Keyword Intent] ì˜ë„: {intent}")
        return {
            "intent": intent,
            "intent_confidence": 0.6,  # í‚¤ì›Œë“œ ê¸°ë°˜ì€ ë‚®ì€ ì‹ ë¢°ë„
        }

    llm = ChatAnthropic(
        model="claude-3-5-haiku-20241022",
        api_key=api_key,
        temperature=0
    )

    # Structured Output ì„¤ì •
    structured_llm = llm.with_structured_output(IntentAnalysis)

    # Intent ë¶„ì„ í”„ë¡¬í”„íŠ¸
    prompt = f"""ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

ì‚¬ìš©ì ì¿¼ë¦¬: "{query}"

ì˜ë„ ì¹´í…Œê³ ë¦¬:
- stock_analysis: ì¢…ëª© ë¶„ì„ ë° í‰ê°€
- trade_execution: ë§¤ìˆ˜/ë§¤ë„ ì‹¤í–‰
- portfolio_evaluation: í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€
- rebalancing: ë¦¬ë°¸ëŸ°ì‹± ë° ì¬êµ¬ì„±
- performance_check: ìˆ˜ìµë¥  ë° í˜„í™© ì¡°íšŒ
- market_status: ì‹œì¥ ìƒí™© ë¶„ì„
- general_question: ì¼ë°˜ ì§ˆë¬¸

ì¢…ëª© ì •ë³´ê°€ ìˆë‹¤ë©´ ì¶”ì¶œí•˜ì„¸ìš” (ì¢…ëª©ëª… ë˜ëŠ” ì¢…ëª©ì½”ë“œ).
ë¶„ì„ ì‹ ë¢°ë„ë„ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”."""

    try:
        # LLM í˜¸ì¶œ
        analysis: IntentAnalysis = await structured_llm.ainvoke([HumanMessage(content=prompt)])

        logger.info(f"ğŸ” [LLM Intent] ì˜ë„: {analysis.intent}, ì¢…ëª©: {analysis.stock_name or analysis.stock_code}, ì‹ ë¢°ë„: {analysis.confidence:.2f}")

        return {
            "intent": analysis.intent,
            "stock_code": analysis.stock_code,
            "stock_name": analysis.stock_name,
            "intent_confidence": analysis.confidence,
        }

    except Exception as e:
        logger.error(f"âŒ [LLM Intent] ë¶„ì„ ì‹¤íŒ¨: {e}")
        # Fallback: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
        return {
            "intent": "general_question",
            "intent_confidence": 0.0,
        }


# ==================== LLM ê¸°ë°˜ Supervisor ë…¸ë“œ ====================

async def llm_supervisor_node(state: GraphState) -> GraphState:
    """
    GPT-5 nano ê¸°ë°˜ Supervisor ë…¸ë“œ

    Intentì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜¸ì¶œí•  ì—ì´ì „íŠ¸ë¥¼ ììœ¨ì ìœ¼ë¡œ ì„ íƒ
    """
    intent = state.get("intent", "general_question")
    query = state["messages"][-1].content if hasattr(state["messages"][-1], 'content') else str(state["messages"][-1])
    stock_info = state.get("stock_name") or state.get("stock_code") or ""

    # Claude LLM ì´ˆê¸°í™”
    from langchain_anthropic import ChatAnthropic
    import os

    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        logger.error(f"âŒ [LLM Supervisor] ANTHROPIC_API_KEY not found")
        # Fallback: ì˜ë„ ê¸°ë°˜ ê¸°ë³¸ ë¼ìš°íŒ…
        fallback_routing = {
            "stock_analysis": ["research_agent", "strategy_agent", "risk_agent"],
            "trade_execution": ["strategy_agent", "risk_agent"],
            "portfolio_evaluation": ["portfolio_agent", "risk_agent"],
            "rebalancing": ["portfolio_agent", "strategy_agent", "risk_agent"],
            "performance_check": ["portfolio_agent"],
            "market_status": ["research_agent", "monitoring_agent"],
            "general_question": ["education_agent"],
        }
        agents = fallback_routing.get(intent, ["education_agent"])
        return {
            "agents_to_call": agents,
            "supervisor_reasoning": "Fallback routing (no API key)",
        }

    llm = ChatAnthropic(
        model="claude-3-5-haiku-20241022",
        api_key=api_key,
        temperature=0
    )

    # Structured Output ì„¤ì •
    structured_llm = llm.with_structured_output(AgentSelection)

    # Supervisor í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ì‚¬ìš©ì ì¿¼ë¦¬: "{query}"
íŒŒì•…ëœ ì˜ë„: {intent}
ì¢…ëª© ì •ë³´: {stock_info or 'ì—†ìŒ'}

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
- research_agent: ì¢…ëª© ë¶„ì„, ì¬ë¬´ì œí‘œ, ë‰´ìŠ¤ ë¶„ì„
- strategy_agent: íˆ¬ì ì „ëµ ìˆ˜ë¦½, ì‹œì¥ ë¶„ì„, ìì‚° ë°°ë¶„
- risk_agent: ë¦¬ìŠ¤í¬ í‰ê°€ ë° ê´€ë¦¬
- portfolio_agent: í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë° í‰ê°€, ë¦¬ë°¸ëŸ°ì‹±
- monitoring_agent: ì‹œì¥ ëª¨ë‹ˆí„°ë§, ì‹¤ì‹œê°„ ë°ì´í„°
- education_agent: íˆ¬ì êµìœ¡ ë° ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€

í•„ìš”í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”."""

    try:
        # LLM í˜¸ì¶œ
        selection: AgentSelection = await structured_llm.ainvoke([HumanMessage(content=prompt)])

        logger.info(f"ğŸ¯ [LLM Supervisor] ì„ íƒëœ ì—ì´ì „íŠ¸: {selection.agents}")
        logger.info(f"ğŸ’¡ [LLM Supervisor] ì„ íƒ ì´ìœ : {selection.reasoning}")

        return {
            "agents_to_call": selection.agents,
            "supervisor_reasoning": selection.reasoning,
        }

    except Exception as e:
        logger.error(f"âŒ [LLM Supervisor] ì„ íƒ ì‹¤íŒ¨: {e}")
        # Fallback: ì˜ë„ ê¸°ë°˜ ê¸°ë³¸ ë¼ìš°íŒ…
        fallback_routing = {
            "stock_analysis": ["research_agent", "strategy_agent", "risk_agent"],
            "trade_execution": ["strategy_agent", "risk_agent"],
            "portfolio_evaluation": ["portfolio_agent", "risk_agent"],
            "rebalancing": ["portfolio_agent", "strategy_agent", "risk_agent"],
            "performance_check": ["portfolio_agent"],
            "market_status": ["research_agent", "monitoring_agent"],
            "general_question": ["education_agent"],
        }

        agents = fallback_routing.get(intent, ["education_agent"])
        return {
            "agents_to_call": agents,
            "supervisor_reasoning": "Fallback routing based on intent",
        }
