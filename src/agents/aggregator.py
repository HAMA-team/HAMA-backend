"""
Aggregator - ë‹µë³€ ê°œì¸í™”

ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ì í”„ë¡œíŒŒì¼ì— ë§ê²Œ ì¡°ì ˆí•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±
"""
import json
import logging
from typing import Dict, Any, Optional

from langchain_core.messages import BaseMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from src.config.settings import settings
from src.utils.llm_factory import get_llm

logger = logging.getLogger(__name__)


async def personalize_response(
    agent_results: Dict[str, Any],
    user_profile: Dict[str, Any],
    routing_decision: Optional[Dict[str, Any]] = None,
    config: Optional[RunnableConfig] = None,
) -> Dict[str, Any]:
    """
    ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ì í”„ë¡œíŒŒì¼ì— ë§ê²Œ ê°œì¸í™”

    Args:
        agent_results: ê° ì—ì´ì „íŠ¸ì˜ ì›ë³¸ ê²°ê³¼
            ì˜ˆ: {"research": {...}, "strategy": {...}}
        user_profile: ì‚¬ìš©ì í”„ë¡œíŒŒì¼
        routing_decision: Router íŒë‹¨ (depth_level, personalization ë“±)

    Returns:
        ê°œì¸í™”ëœ ìµœì¢… ì‘ë‹µ
    """
    logger.info("ğŸ¨ [Aggregator] ë‹µë³€ ê°œì¸í™” ì‹œì‘")

    # í”„ë¡œíŒŒì¼ ì •ë³´ ì¶”ì¶œ
    expertise_level = user_profile.get("expertise_level", "intermediate")
    technical_level = user_profile.get("technical_level", "intermediate")
    wants_explanations = user_profile.get("wants_explanations", True)
    wants_analogies = user_profile.get("wants_analogies", False)

    # Router íŒë‹¨ ì •ë³´
    depth_level = "detailed"
    personalization_settings = {}
    if routing_decision:
        depth_level = routing_decision.get("depth_level", "detailed")
        personalization = routing_decision.get("personalization")
        if hasattr(personalization, "model_dump"):
            personalization_settings = personalization.model_dump()
        elif isinstance(personalization, dict):
            personalization_settings = personalization

    # ê°œì¸í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    personalization_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ íˆ¬ì ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë§ê²Œ ì „ë‹¬í•˜ëŠ” Aggregatorì…ë‹ˆë‹¤.

**ì‚¬ìš©ì í”„ë¡œíŒŒì¼:**
- íˆ¬ì ê²½í—˜: {expertise_level}
- ê¸°ìˆ ì  ì´í•´ë„: {technical_level}
- ìš©ì–´ ì„¤ëª… í•„ìš”: {wants_explanations}
- ë¹„ìœ  ì„ í˜¸: {wants_analogies}

**ê°œì¸í™” ì›ì¹™:**

âš ï¸ **ì¤‘ìš”: ì ˆëŒ€ë¡œ ì˜ˆì‹œì˜ ìˆ«ìë‚˜ ê°€ê²©ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ ì—ì´ì „íŠ¸ ê²°ê³¼ì˜ ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.**

1. **ì´ˆë³´ì (beginner):**
   - ì „ë¬¸ ìš©ì–´ ì„¤ëª… ì¶”ê°€
   - ë¹„ìœ  ì‚¬ìš© (ì˜ˆ: "PERì€ ì£¼ì‹ì˜ ê°€ê²©í‘œ ê°™ì€ ê²ƒ")
   - ë‹¨ìˆœí™”ëœ í‘œí˜„
   - í•µì‹¬ë§Œ 1-2ê°œ
   - ê²°ë¡ ì„ ëª…í™•í•˜ê²Œ

2. **ì¤‘ê¸‰ì (intermediate):**
   - ì£¼ìš” ì§€í‘œ ì¤‘ì‹¬ (3-5ê°œ)
   - ê°„ë‹¨í•œ ì„¤ëª…ë§Œ
   - ê·¼ê±° í¬í•¨
   - ë¹„êµ ë¶„ì„ (ì—…ì¢… í‰ê· )

3. **ì „ë¬¸ê°€ (expert):**
   - ì›ë°ì´í„° ì œê³µ
   - ê³„ì‚° ê³¼ì • í¬í•¨
   - ëª¨ë“  ì§€í‘œ
   - ë¯¼ê°ë„ ë¶„ì„
   - ì •ëŸ‰ì  ê·¼ê±°

**ë‹µë³€ ê¹Šì´ ìˆ˜ì¤€: {depth_level}**
- brief: 1-2ë¬¸ì¥, í•µì‹¬ë§Œ
- detailed: 3-5ê°œ ì§€í‘œ, ê·¼ê±° í¬í•¨
- comprehensive: ëª¨ë“  ì§€í‘œ, ê³„ì‚° ê³¼ì •

**ì—ì´ì „íŠ¸ ê²°ê³¼:**
{agent_results}

ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ì í”„ë¡œíŒŒì¼ì— ë§ê²Œ ì¬êµ¬ì„±í•˜ì„¸ìš”.
ì‘ë‹µì€ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""),
        ("human", "ì‚¬ìš©ìì—ê²Œ ë§ê²Œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    ])

    def _serialize(value: Any) -> Any:
        """
        LangChain ë©”ì‹œì§€ ë“± JSON ì§ë ¬í™” ë¶ˆê°€ ê°ì²´ë¥¼ ì•ˆì „í•œ í˜•íƒœë¡œ ë³€í™˜
        """
        if isinstance(value, BaseMessage):
            return {
                "type": value.type,
                "content": value.content,
            }
        if isinstance(value, dict):
            return {key: _serialize(val) for key, val in value.items()}
        if isinstance(value, (list, tuple, set)):
            return [_serialize(item) for item in value]
        return value

    serializable_results = _serialize(agent_results)

    # LLM í˜¸ì¶œ (í™˜ê²½ì— ë§ëŠ” provider/model ì‚¬ìš©)
    llm = get_llm(
        temperature=0.3,
        model=settings.llm_model_name,
    )
    personalization_chain = personalization_prompt | llm

    prompt_inputs = {
        "expertise_level": expertise_level,
        "technical_level": technical_level,
        "wants_explanations": "ì˜ˆ" if wants_explanations else "ì•„ë‹ˆì˜¤",
        "wants_analogies": "ì˜ˆ" if wants_analogies else "ì•„ë‹ˆì˜¤",
        "depth_level": depth_level,
        "agent_results": json.dumps(serializable_results, ensure_ascii=False, indent=2),
    }

    try:
        if config is not None:
            response_message = await personalization_chain.ainvoke(prompt_inputs, config=config)
        else:
            response_message = await personalization_chain.ainvoke(prompt_inputs)

        personalized_response = (
            response_message.content
            if hasattr(response_message, "content")
            else str(response_message)
        )

        logger.info("âœ… [Aggregator] ê°œì¸í™” ì™„ë£Œ")

        return {
            "success": True,
            "response": personalized_response,
            "metadata": {
                "expertise_level": expertise_level,
                "depth_level": depth_level,
                "personalization_applied": True
            }
        }

    except Exception as e:
        logger.error(f"âŒ [Aggregator] ì—ëŸ¬: {e}")

        # Fallback: ì›ë³¸ ê²°ê³¼ ë°˜í™˜
        fallback_response = json.dumps(serializable_results, ensure_ascii=False, indent=2)

        return {
            "success": False,
            "response": fallback_response,
            "error": str(e),
            "metadata": {
                "expertise_level": expertise_level,
                "depth_level": depth_level,
                "personalization_applied": False
            }
        }


async def aggregate_multi_agent_results(
    query: str,
    agent_results: Dict[str, Any],
    user_profile: Dict[str, Any],
    routing_decision: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ê²°ê³¼ í†µí•© ë° ê°œì¸í™”

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        agent_results: ê° ì—ì´ì „íŠ¸ ê²°ê³¼
            ì˜ˆ: {
                "research": {...},
                "strategy": {...},
                "risk": {...}
            }
        user_profile: ì‚¬ìš©ì í”„ë¡œíŒŒì¼
        routing_decision: Router íŒë‹¨

    Returns:
        í†µí•© ë° ê°œì¸í™”ëœ ìµœì¢… ì‘ë‹µ
    """
    logger.info(f"ğŸ”— [Aggregator] ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê²°ê³¼ í†µí•©: {list(agent_results.keys())}")

    # 1. ê²°ê³¼ í†µí•©
    # TODO: ì—ì´ì „íŠ¸ ê°„ ê²°ê³¼ ì¡°í•© ë¡œì§ (í˜„ì¬ëŠ” ë‹¨ìˆœ ë³‘í•©)

    # 2. ê°œì¸í™”
    personalized = await personalize_response(
        agent_results=agent_results,
        user_profile=user_profile,
        routing_decision=routing_decision
    )

    return {
        **personalized,
        "query": query,
        "agents_called": list(agent_results.keys())
    }
