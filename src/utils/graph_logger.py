"""
LangGraph ì‹¤í–‰ ê°€ì‹œì„±ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ë¡œê±°
LangSmith ì—†ì´ë„ ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ì¶”ì í•  ìˆ˜ ìˆìŒ
"""
import json
import time
from typing import Any, Dict
from datetime import datetime
from pathlib import Path


class GraphLogger:
    """ê·¸ë˜í”„ ì‹¤í–‰ì„ ë¡œê¹…í•˜ëŠ” ìœ í‹¸ë¦¬í‹°"""

    def __init__(self, log_dir: str = "logs/graph_executions"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.current_execution = None
        self.start_time = None

    def start_execution(self, graph_name: str, input_data: Dict[str, Any]):
        """ì‹¤í–‰ ì‹œì‘"""
        self.start_time = time.time()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        self.current_execution = {
            "graph_name": graph_name,
            "timestamp": timestamp,
            "input": self._serialize(input_data),
            "nodes": [],
            "errors": []
        }

        print(f"\n{'='*60}")
        print(f"ğŸš€ [{graph_name}] ì‹¤í–‰ ì‹œì‘")
        print(f"{'='*60}")

    def log_node_start(self, node_name: str, state: Dict[str, Any]):
        """ë…¸ë“œ ì‹¤í–‰ ì‹œì‘"""
        node_start = time.time()

        print(f"\nâ–¶ï¸  ë…¸ë“œ: {node_name}")
        print(f"   ìƒíƒœ í‚¤: {list(state.keys())}")

        node_log = {
            "node": node_name,
            "start_time": node_start,
            "input_state": self._serialize(state, max_depth=2)
        }

        if self.current_execution:
            self.current_execution["nodes"].append(node_log)

        return node_start

    def log_node_end(self, node_name: str, node_start: float, output_state: Dict[str, Any]):
        """ë…¸ë“œ ì‹¤í–‰ ì¢…ë£Œ"""
        duration = time.time() - node_start

        print(f"   âœ… ì™„ë£Œ ({duration:.2f}s)")

        if self.current_execution and self.current_execution["nodes"]:
            # ë§ˆì§€ë§‰ ë…¸ë“œ ë¡œê·¸ ì—…ë°ì´íŠ¸
            self.current_execution["nodes"][-1].update({
                "duration": duration,
                "output_state": self._serialize(output_state, max_depth=2)
            })

    def log_llm_call(self, model: str, prompt: str, response: str, tokens: int = None):
        """LLM í˜¸ì¶œ ë¡œê¹…"""
        print(f"   ğŸ¤– LLM í˜¸ì¶œ: {model}")
        if tokens:
            print(f"      í† í°: {tokens}")

        if self.current_execution and self.current_execution["nodes"]:
            if "llm_calls" not in self.current_execution["nodes"][-1]:
                self.current_execution["nodes"][-1]["llm_calls"] = []

            self.current_execution["nodes"][-1]["llm_calls"].append({
                "model": model,
                "prompt_preview": prompt[:100] + "...",
                "response_preview": response[:100] + "...",
                "tokens": tokens
            })

    def log_error(self, node_name: str, error: Exception):
        """ì—ëŸ¬ ë¡œê¹…"""
        print(f"   âŒ ì—ëŸ¬: {str(error)}")

        if self.current_execution:
            self.current_execution["errors"].append({
                "node": node_name,
                "error": str(error),
                "type": type(error).__name__
            })

    def end_execution(self, final_state: Dict[str, Any]):
        """ì‹¤í–‰ ì¢…ë£Œ"""
        total_duration = time.time() - self.start_time

        print(f"\n{'='*60}")
        print(f"âœ… ì‹¤í–‰ ì™„ë£Œ (ì´ {total_duration:.2f}s)")
        print(f"{'='*60}\n")

        if self.current_execution:
            self.current_execution.update({
                "total_duration": total_duration,
                "final_state": self._serialize(final_state, max_depth=2)
            })

            # ë¡œê·¸ íŒŒì¼ ì €ì¥
            log_file = self.log_dir / f"{self.current_execution['timestamp']}_{self.current_execution['graph_name']}.json"
            with open(log_file, "w", encoding="utf-8") as f:
                json.dump(self.current_execution, f, indent=2, ensure_ascii=False)

            print(f"ğŸ“ ë¡œê·¸ ì €ì¥: {log_file}")

    def _serialize(self, obj: Any, max_depth: int = 3, current_depth: int = 0) -> Any:
        """ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if current_depth > max_depth:
            return "..."

        if isinstance(obj, dict):
            return {k: self._serialize(v, max_depth, current_depth + 1) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._serialize(item, max_depth, current_depth + 1) for item in obj]
        elif hasattr(obj, "__dict__"):
            return f"<{type(obj).__name__}>"
        else:
            return str(obj) if not isinstance(obj, (str, int, float, bool, type(None))) else obj


# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
graph_logger = GraphLogger()


def log_graph_execution(func):
    """ê·¸ë˜í”„ ì‹¤í–‰ì„ ìë™ìœ¼ë¡œ ë¡œê¹…í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
    async def wrapper(*args, **kwargs):
        graph_name = func.__name__
        input_data = kwargs if kwargs else {"args": args}

        graph_logger.start_execution(graph_name, input_data)

        try:
            result = await func(*args, **kwargs)
            graph_logger.end_execution(result)
            return result
        except Exception as e:
            graph_logger.log_error(graph_name, e)
            raise

    return wrapper
