"""
ìµœì í™” íš¨ê³¼ ì¸¡ì • í…ŒìŠ¤íŠ¸

Phase 1, 2 ìµœì í™” ì ìš© í›„ ì‹¤ì œ ê°œì„  íš¨ê³¼ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤:
- LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹± íš¨ê³¼
- ê·¸ë˜í”„ ì»´íŒŒì¼ ìºì‹± íš¨ê³¼
- ì „ì²´ E2E ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥

ê²°ê³¼ëŠ” docs/optimization_results_{timestamp}.mdì— ì €ì¥ë©ë‹ˆë‹¤.
"""
import asyncio
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
import pytest

from src.utils.llm_factory import get_llm, _build_llm
from src.agents.graph_master import run_graph, get_compiled_graph, build_graph


class OptimizationMetrics:
    """ìµœì í™” ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í´ë˜ìŠ¤"""

    def __init__(self):
        self.reset()

    def reset(self):
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        self.llm_cache_info = None
        self.graph_cache_info = None
        self.execution_times: List[float] = []
        self.step_results: List[Dict[str, Any]] = []

    def record_step(self, step_name: str, duration: float, metadata: Dict[str, Any] = None):
        """ë‹¨ê³„ë³„ ê²°ê³¼ ê¸°ë¡"""
        self.execution_times.append(duration)
        result = {
            "step": step_name,
            "duration_sec": round(duration, 3),
            "metadata": metadata or {}
        }
        self.step_results.append(result)

    def capture_cache_info(self):
        """ìºì‹œ ì •ë³´ ìˆ˜ì§‘"""
        self.llm_cache_info = _build_llm.cache_info()
        self.graph_cache_info = get_compiled_graph.cache_info()

    def generate_report(self) -> str:
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± (Markdown)"""
        self.capture_cache_info()

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        report = f"""# ìµœì í™” íš¨ê³¼ ì¸¡ì • ë¦¬í¬íŠ¸

**ì¸¡ì • ì¼ì‹œ**: {timestamp}

## ğŸ“Š ì „ì²´ ìš”ì•½

| í•­ëª© | ê°’ |
|------|------|
| ì´ ì‹¤í–‰ ì‹œê°„ | {sum(self.execution_times):.3f}ì´ˆ |
| í‰ê·  ì‹¤í–‰ ì‹œê°„ | {sum(self.execution_times) / len(self.execution_times):.3f}ì´ˆ |
| ì´ ë‹¨ê³„ ìˆ˜ | {len(self.step_results)} |

## ğŸš€ ìºì‹œ ì„±ëŠ¥

### LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹±

```
Cache Info: {self.llm_cache_info}
```

| ë©”íŠ¸ë¦­ | ê°’ |
|--------|------|
| ìºì‹œ íˆíŠ¸ | {self.llm_cache_info.hits if self.llm_cache_info else 0} |
| ìºì‹œ ë¯¸ìŠ¤ | {self.llm_cache_info.misses if self.llm_cache_info else 0} |
| í˜„ì¬ ìºì‹œ í¬ê¸° | {self.llm_cache_info.currsize if self.llm_cache_info else 0} |
| ìµœëŒ€ ìºì‹œ í¬ê¸° | {self.llm_cache_info.maxsize if self.llm_cache_info else 0} |
| **íˆíŠ¸ìœ¨** | **{self.llm_cache_info.hits / (self.llm_cache_info.hits + self.llm_cache_info.misses) * 100 if self.llm_cache_info and (self.llm_cache_info.hits + self.llm_cache_info.misses) > 0 else 0:.1f}%** |

### ê·¸ë˜í”„ ì»´íŒŒì¼ ìºì‹±

```
Cache Info: {self.graph_cache_info}
```

| ë©”íŠ¸ë¦­ | ê°’ |
|--------|------|
| ìºì‹œ íˆíŠ¸ | {self.graph_cache_info.hits if self.graph_cache_info else 0} |
| ìºì‹œ ë¯¸ìŠ¤ | {self.graph_cache_info.misses if self.graph_cache_info else 0} |
| í˜„ì¬ ìºì‹œ í¬ê¸° | {self.graph_cache_info.currsize if self.graph_cache_info else 0} |
| ìµœëŒ€ ìºì‹œ í¬ê¸° | {self.graph_cache_info.maxsize if self.graph_cache_info else 0} |
| **íˆíŠ¸ìœ¨** | **{self.graph_cache_info.hits / (self.graph_cache_info.hits + self.graph_cache_info.misses) * 100 if self.graph_cache_info and (self.graph_cache_info.hits + self.graph_cache_info.misses) > 0 else 0:.1f}%** |

## â±ï¸ ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„

| ë‹¨ê³„ | ì‹¤í–‰ ì‹œê°„ (ì´ˆ) | ë¹„ê³  |
|------|---------------|------|
"""

        for result in self.step_results:
            metadata_str = ", ".join([f"{k}={v}" for k, v in result['metadata'].items()])
            report += f"| {result['step']} | {result['duration_sec']:.3f} | {metadata_str} |\n"

        report += f"""
## ğŸ“ˆ ë¶„ì„

### ì˜ˆìƒ ê°œì„  íš¨ê³¼

**Before (ìµœì í™” ì „ ì˜ˆìƒ):**
- ë§¤ `run_graph()` í˜¸ì¶œë§ˆë‹¤ ìƒˆ ê·¸ë˜í”„ ë¹Œë“œ
- ë§¤ ë…¸ë“œë§ˆë‹¤ ìƒˆ LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
- ì˜ˆìƒ ì´ ì‹œê°„: ~5ë¶„ (20íšŒ í˜¸ì¶œ ì‹œ)

**After (ìµœì í™” í›„ ì‹¤ì¸¡):**
- ê·¸ë˜í”„ ìºì‹œ íˆíŠ¸ìœ¨: **{self.graph_cache_info.hits / (self.graph_cache_info.hits + self.graph_cache_info.misses) * 100 if self.graph_cache_info and (self.graph_cache_info.hits + self.graph_cache_info.misses) > 0 else 0:.1f}%**
- LLM ìºì‹œ íˆíŠ¸ìœ¨: **{self.llm_cache_info.hits / (self.llm_cache_info.hits + self.llm_cache_info.misses) * 100 if self.llm_cache_info and (self.llm_cache_info.hits + self.llm_cache_info.misses) > 0 else 0:.1f}%**
- ì‹¤ì¸¡ ì´ ì‹œê°„: **{sum(self.execution_times):.3f}ì´ˆ**

### í•µì‹¬ ì§€í‘œ

1. **ê·¸ë˜í”„ ì¬ì‚¬ìš©ë¥ **: {self.graph_cache_info.hits if self.graph_cache_info else 0} / {(self.graph_cache_info.hits + self.graph_cache_info.misses) if self.graph_cache_info else 0}
2. **LLM ì¬ì‚¬ìš©ë¥ **: {self.llm_cache_info.hits if self.llm_cache_info else 0} / {(self.llm_cache_info.hits + self.llm_cache_info.misses) if self.llm_cache_info else 0}
3. **í‰ê·  ì‘ë‹µ ì‹œê°„**: {sum(self.execution_times) / len(self.execution_times):.3f}ì´ˆ

## ğŸ¯ ê²°ë¡ 

"""

        # ìë™ ë¶„ì„
        if self.graph_cache_info and self.graph_cache_info.hits > 0:
            graph_hit_rate = self.graph_cache_info.hits / (self.graph_cache_info.hits + self.graph_cache_info.misses) * 100
            if graph_hit_rate > 80:
                report += "âœ… **ê·¸ë˜í”„ ìºì‹± íš¨ê³¼ ìš°ìˆ˜**: 80% ì´ìƒì˜ íˆíŠ¸ìœ¨ë¡œ ê·¸ë˜í”„ ì¬ë¹Œë“œ ì˜¤ë²„í—¤ë“œê°€ í¬ê²Œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.\n\n"
            elif graph_hit_rate > 50:
                report += "âš ï¸ **ê·¸ë˜í”„ ìºì‹± íš¨ê³¼ ë³´í†µ**: 50~80% íˆíŠ¸ìœ¨ì…ë‹ˆë‹¤. automation_level ë³€ê²½ì´ ë§ì€ ê²½ìš°ì…ë‹ˆë‹¤.\n\n"
            else:
                report += "âŒ **ê·¸ë˜í”„ ìºì‹± ë¯¸í¡**: 50% ë¯¸ë§Œ íˆíŠ¸ìœ¨ì…ë‹ˆë‹¤. ìºì‹± ë¡œì§ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\n"

        if self.llm_cache_info and self.llm_cache_info.hits > 0:
            llm_hit_rate = self.llm_cache_info.hits / (self.llm_cache_info.hits + self.llm_cache_info.misses) * 100
            if llm_hit_rate > 80:
                report += "âœ… **LLM ìºì‹± íš¨ê³¼ ìš°ìˆ˜**: 80% ì´ìƒì˜ íˆíŠ¸ìœ¨ë¡œ LLM ì´ˆê¸°í™” ì˜¤ë²„í—¤ë“œê°€ í¬ê²Œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.\n\n"
            elif llm_hit_rate > 50:
                report += "âš ï¸ **LLM ìºì‹± íš¨ê³¼ ë³´í†µ**: 50~80% íˆíŠ¸ìœ¨ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ temperature/max_tokens ì¡°í•©ì´ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
            else:
                report += "âŒ **LLM ìºì‹± ë¯¸í¡**: 50% ë¯¸ë§Œ íˆíŠ¸ìœ¨ì…ë‹ˆë‹¤. íŒŒë¼ë¯¸í„° í‘œì¤€í™” ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\n"

        report += f"""
**ì´ ì‹¤í–‰ ì‹œê°„**: {sum(self.execution_times):.3f}ì´ˆ

---

*ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

        return report

    def save_report(self, output_dir: str = "docs"):
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        report = self.generate_report()

        Path(output_dir).mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"optimization_results_{timestamp}.md"
        filepath = Path(output_dir) / filename

        filepath.write_text(report, encoding="utf-8")

        print(f"\n{'='*80}")
        print(f"ğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
        print(f"{'='*80}\n")

        return str(filepath)


# ==================== í…ŒìŠ¤íŠ¸ ì‹œì‘ ====================

@pytest.fixture
def metrics():
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    return OptimizationMetrics()


class TestOptimizationMetrics:
    """ìµœì í™” íš¨ê³¼ ì¸¡ì • í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_llm_caching_effect(self, metrics: OptimizationMetrics):
        """
        Phase 1: LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹± íš¨ê³¼ ì¸¡ì •

        ê°™ì€ ì„¤ì •ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ ì‹œ ìºì‹œì—ì„œ ë°˜í™˜ë˜ëŠ”ì§€ í™•ì¸
        """
        print("\n" + "="*80)
        print("ğŸ“Š Phase 1: LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹± íš¨ê³¼ ì¸¡ì •")
        print("="*80)

        # ì´ˆê¸° ìºì‹œ ì •ë³´ ìˆ˜ì§‘
        metrics.capture_cache_info()
        initial_llm_cache = metrics.llm_cache_info

        print(f"\nì´ˆê¸° LLM ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {initial_llm_cache.hits if initial_llm_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {initial_llm_cache.misses if initial_llm_cache else 0}")

        # í…ŒìŠ¤íŠ¸ 1: ê°™ì€ ì„¤ì •ìœ¼ë¡œ 10ë²ˆ í˜¸ì¶œ
        print(f"\n[í…ŒìŠ¤íŠ¸ 1] ê°™ì€ ì„¤ì •(temp=0, tokens=4000)ìœ¼ë¡œ 10ë²ˆ í˜¸ì¶œ")

        start = time.time()
        for i in range(10):
            llm = get_llm(temperature=0, max_tokens=4000)
            assert llm is not None
        duration = time.time() - start

        metrics.record_step(
            "LLM ìºì‹± - ê°™ì€ ì„¤ì • 10íšŒ",
            duration,
            {"calls": 10, "config": "temp=0, tokens=4000"}
        )

        print(f"  âœ… ì™„ë£Œ: {duration:.3f}ì´ˆ")

        # ì¤‘ê°„ ìºì‹œ ì •ë³´
        metrics.capture_cache_info()
        mid_llm_cache = metrics.llm_cache_info

        print(f"\nì¤‘ê°„ LLM ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {mid_llm_cache.hits if mid_llm_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {mid_llm_cache.misses if mid_llm_cache else 0}")
        print(f"  - ìºì‹œ ì¦ê°€: +{(mid_llm_cache.hits - initial_llm_cache.hits) if (mid_llm_cache and initial_llm_cache) else 0}ê°œ")

        # í…ŒìŠ¤íŠ¸ 2: ë‹¤ë¥¸ ì„¤ì •ìœ¼ë¡œ 5ë²ˆ í˜¸ì¶œ
        print(f"\n[í…ŒìŠ¤íŠ¸ 2] ë‹¤ë¥¸ ì„¤ì •(temp=0.3, tokens=2000)ìœ¼ë¡œ 5ë²ˆ í˜¸ì¶œ")

        start = time.time()
        for i in range(5):
            llm = get_llm(temperature=0.3, max_tokens=2000)
            assert llm is not None
        duration = time.time() - start

        metrics.record_step(
            "LLM ìºì‹± - ë‹¤ë¥¸ ì„¤ì • 5íšŒ",
            duration,
            {"calls": 5, "config": "temp=0.3, tokens=2000"}
        )

        print(f"  âœ… ì™„ë£Œ: {duration:.3f}ì´ˆ")

        # ìµœì¢… ìºì‹œ ì •ë³´
        metrics.capture_cache_info()
        final_llm_cache = metrics.llm_cache_info

        print(f"\nìµœì¢… LLM ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {final_llm_cache.hits if final_llm_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {final_llm_cache.misses if final_llm_cache else 0}")
        print(f"  - í˜„ì¬ í¬ê¸°: {final_llm_cache.currsize if final_llm_cache else 0}")

        if final_llm_cache and (final_llm_cache.hits + final_llm_cache.misses) > 0:
            hit_rate = final_llm_cache.hits / (final_llm_cache.hits + final_llm_cache.misses) * 100
            print(f"  - íˆíŠ¸ìœ¨: {hit_rate:.1f}%")

            # ê²€ì¦
            assert hit_rate > 50, f"LLM ìºì‹œ íˆíŠ¸ìœ¨ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤: {hit_rate:.1f}%"

    @pytest.mark.asyncio
    async def test_graph_caching_effect(self, metrics: OptimizationMetrics):
        """
        Phase 2: ê·¸ë˜í”„ ì»´íŒŒì¼ ìºì‹± íš¨ê³¼ ì¸¡ì •

        ê°™ì€ automation_levelë¡œ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ ì‹œ ìºì‹œì—ì„œ ë°˜í™˜ë˜ëŠ”ì§€ í™•ì¸
        """
        print("\n" + "="*80)
        print("ğŸ“Š Phase 2: ê·¸ë˜í”„ ì»´íŒŒì¼ ìºì‹± íš¨ê³¼ ì¸¡ì •")
        print("="*80)

        # ì´ˆê¸° ìºì‹œ ì •ë³´
        metrics.capture_cache_info()
        initial_graph_cache = metrics.graph_cache_info

        print(f"\nì´ˆê¸° ê·¸ë˜í”„ ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {initial_graph_cache.hits if initial_graph_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {initial_graph_cache.misses if initial_graph_cache else 0}")

        # í…ŒìŠ¤íŠ¸ 1: ê°™ì€ ë ˆë²¨ë¡œ 10ë²ˆ ë¹Œë“œ
        print(f"\n[í…ŒìŠ¤íŠ¸ 1] automation_level=2ë¡œ 10ë²ˆ ë¹Œë“œ")

        start = time.time()
        for i in range(10):
            app = build_graph(automation_level=2)
            assert app is not None
        duration = time.time() - start

        metrics.record_step(
            "ê·¸ë˜í”„ ìºì‹± - ë ˆë²¨2 10íšŒ",
            duration,
            {"calls": 10, "level": 2}
        )

        print(f"  âœ… ì™„ë£Œ: {duration:.3f}ì´ˆ")

        # ì¤‘ê°„ ìºì‹œ ì •ë³´
        metrics.capture_cache_info()
        mid_graph_cache = metrics.graph_cache_info

        print(f"\nì¤‘ê°„ ê·¸ë˜í”„ ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {mid_graph_cache.hits if mid_graph_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {mid_graph_cache.misses if mid_graph_cache else 0}")
        print(f"  - ìºì‹œ ì¦ê°€: +{(mid_graph_cache.hits - initial_graph_cache.hits) if (mid_graph_cache and initial_graph_cache) else 0}ê°œ")

        # í…ŒìŠ¤íŠ¸ 2: ë‹¤ë¥¸ ë ˆë²¨ë¡œ 5ë²ˆ ë¹Œë“œ
        print(f"\n[í…ŒìŠ¤íŠ¸ 2] automation_level=1ë¡œ 5ë²ˆ ë¹Œë“œ")

        start = time.time()
        for i in range(5):
            app = build_graph(automation_level=1)
            assert app is not None
        duration = time.time() - start

        metrics.record_step(
            "ê·¸ë˜í”„ ìºì‹± - ë ˆë²¨1 5íšŒ",
            duration,
            {"calls": 5, "level": 1}
        )

        print(f"  âœ… ì™„ë£Œ: {duration:.3f}ì´ˆ")

        # ìµœì¢… ìºì‹œ ì •ë³´
        metrics.capture_cache_info()
        final_graph_cache = metrics.graph_cache_info

        print(f"\nìµœì¢… ê·¸ë˜í”„ ìºì‹œ ìƒíƒœ:")
        print(f"  - íˆíŠ¸: {final_graph_cache.hits if final_graph_cache else 0}")
        print(f"  - ë¯¸ìŠ¤: {final_graph_cache.misses if final_graph_cache else 0}")
        print(f"  - í˜„ì¬ í¬ê¸°: {final_graph_cache.currsize if final_graph_cache else 0}")

        if final_graph_cache and (final_graph_cache.hits + final_graph_cache.misses) > 0:
            hit_rate = final_graph_cache.hits / (final_graph_cache.hits + final_graph_cache.misses) * 100
            print(f"  - íˆíŠ¸ìœ¨: {hit_rate:.1f}%")

            # ê²€ì¦
            assert hit_rate > 50, f"ê·¸ë˜í”„ ìºì‹œ íˆíŠ¸ìœ¨ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤: {hit_rate:.1f}%"

    @pytest.mark.asyncio
    async def test_end_to_end_performance(self, metrics: OptimizationMetrics):
        """
        Phase 3: ì „ì²´ E2E ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ì¸¡ì •

        ì‹¤ì œ run_graph() í˜¸ì¶œì„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•˜ì—¬ ì „ì²´ ì„±ëŠ¥ ì¸¡ì •
        """
        print("\n" + "="*80)
        print("ğŸ“Š Phase 3: ì „ì²´ E2E ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ì¸¡ì •")
        print("="*80)

        queries = [
            ("ì•ˆë…•í•˜ì„¸ìš”", 2),
            ("PERì´ ë­ì•¼?", 2),
            ("ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜", 2),
            ("íˆ¬ì ì „ëµ ì¶”ì²œí•´ì¤˜", 2),
            ("ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ì ê²€í•´ì¤˜", 2),
        ]

        for idx, (query, level) in enumerate(queries, 1):
            print(f"\n[ì§ˆì˜ {idx}/{len(queries)}] \"{query}\" (ë ˆë²¨ {level})")

            start = time.time()
            try:
                result = await run_graph(
                    query=query,
                    automation_level=level,
                    request_id=f"opt_test_{idx}"
                )
                duration = time.time() - start

                metrics.record_step(
                    f"E2E - ì§ˆì˜ {idx}",
                    duration,
                    {
                        "query": query[:20],
                        "level": level,
                        "success": True
                    }
                )

                print(f"  âœ… ì™„ë£Œ: {duration:.3f}ì´ˆ")
                print(f"  ì‘ë‹µ: {result.get('message', '')[:100]}...")

            except Exception as e:
                duration = time.time() - start

                metrics.record_step(
                    f"E2E - ì§ˆì˜ {idx}",
                    duration,
                    {
                        "query": query[:20],
                        "level": level,
                        "success": False,
                        "error": str(e)[:50]
                    }
                )

                print(f"  âš ï¸ ì—ëŸ¬: {e}")

            # Rate limit ì¤€ìˆ˜
            await asyncio.sleep(1)

        # ìµœì¢… ìºì‹œ ìƒíƒœ
        metrics.capture_cache_info()

        print(f"\nìµœì¢… ìºì‹œ ìƒíƒœ ì¢…í•©:")
        print(f"  LLM ìºì‹œ:")
        print(f"    - íˆíŠ¸: {metrics.llm_cache_info.hits if metrics.llm_cache_info else 0}")
        print(f"    - ë¯¸ìŠ¤: {metrics.llm_cache_info.misses if metrics.llm_cache_info else 0}")

        print(f"  ê·¸ë˜í”„ ìºì‹œ:")
        print(f"    - íˆíŠ¸: {metrics.graph_cache_info.hits if metrics.graph_cache_info else 0}")
        print(f"    - ë¯¸ìŠ¤: {metrics.graph_cache_info.misses if metrics.graph_cache_info else 0}")


# ==================== ì§ì ‘ ì‹¤í–‰ ====================

if __name__ == "__main__":
    """
    ì§ì ‘ ì‹¤í–‰ ì‹œ ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ë¦¬í¬íŠ¸ ìƒì„±
    """
    async def main():
        print("\n" + "ğŸ¯"*40)
        print("ìµœì í™” íš¨ê³¼ ì¸¡ì • í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("ğŸ¯"*40)

        metrics = OptimizationMetrics()
        test_suite = TestOptimizationMetrics()

        # Phase 1: LLM ìºì‹±
        try:
            print("\n" + "="*80)
            print("Phase 1: LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹± íš¨ê³¼")
            print("="*80)
            await test_suite.test_llm_caching_effect(metrics)
            print("\nâœ… Phase 1 ì™„ë£Œ")
        except Exception as e:
            print(f"\nâŒ Phase 1 ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

        # Phase 2: ê·¸ë˜í”„ ìºì‹±
        try:
            print("\n" + "="*80)
            print("Phase 2: ê·¸ë˜í”„ ì»´íŒŒì¼ ìºì‹± íš¨ê³¼")
            print("="*80)
            await test_suite.test_graph_caching_effect(metrics)
            print("\nâœ… Phase 2 ì™„ë£Œ")
        except Exception as e:
            print(f"\nâŒ Phase 2 ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

        # Phase 3: E2E ì„±ëŠ¥
        try:
            print("\n" + "="*80)
            print("Phase 3: ì „ì²´ E2E ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥")
            print("="*80)
            await test_suite.test_end_to_end_performance(metrics)
            print("\nâœ… Phase 3 ì™„ë£Œ")
        except Exception as e:
            print(f"\nâŒ Phase 3 ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

        # ë¦¬í¬íŠ¸ ìƒì„±
        print("\n" + "="*80)
        print("ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("="*80)

        report_path = metrics.save_report()

        print(f"\n{'='*80}")
        print(f"âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“„ ë¦¬í¬íŠ¸: {report_path}")
        print(f"{'='*80}")

    asyncio.run(main())
