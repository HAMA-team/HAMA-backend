"""LLM ì„¤ì • ë³€ê²½ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
import asyncio
from src.utils.llm_factory import (
    get_router_llm,
    get_research_llm,
    get_strategy_llm,
    get_portfolio_risk_llm,
    get_default_agent_llm,
)


async def test_llm_models():
    """LLM ëª¨ë¸ ì„¤ì • í™•ì¸"""
    print("=" * 80)
    print("LLM ëª¨ë¸ ì„¤ì • ê²€ì¦ (ë¹„ìš© ìµœì í™” - Haiku 4.5 + í”„ë¡¬í”„íŠ¸ ìºì‹±)")
    print("=" * 80)

    # 1. Router LLM í™•ì¸
    print("\n1. Router Agent LLM (Claude Haiku 4.5 + ìºì‹±):")
    try:
        router_llm = get_router_llm(temperature=0, max_tokens=100)
        print(f"   âœ… Model: {router_llm.model}")
        print(f"   âœ… Type: {type(router_llm).__name__}")
        print(f"   âœ… ìºì‹±: {router_llm.default_headers.get('anthropic-beta', 'N/A')}")
        assert router_llm.model == "claude-haiku-4-5-20251001", f"Expected claude-haiku-4-5-20251001, got {router_llm.model}"
    except Exception as e:
        print(f"   âŒ Error: {e}")

    # 2. Research LLM í™•ì¸
    print("\n2. Research Agent LLM (Claude Haiku 4.5 + ìºì‹±):")
    try:
        research_llm = get_research_llm(temperature=0, max_tokens=100)
        print(f"   âœ… Model: {research_llm.model}")
        print(f"   âœ… Type: {type(research_llm).__name__}")
        print(f"   âœ… ìºì‹±: {research_llm.default_headers.get('anthropic-beta', 'N/A')}")
        assert research_llm.model == "claude-haiku-4-5-20251001", f"Expected claude-haiku-4-5-20251001, got {research_llm.model}"
    except Exception as e:
        print(f"   âŒ Error: {e}")

    # 3. Strategy LLM í™•ì¸
    print("\n3. Strategy Agent LLM (Claude Haiku 4.5 + ìºì‹±):")
    try:
        strategy_llm = get_strategy_llm(temperature=0, max_tokens=100)
        print(f"   âœ… Model: {strategy_llm.model}")
        print(f"   âœ… Type: {type(strategy_llm).__name__}")
        print(f"   âœ… ìºì‹±: {strategy_llm.default_headers.get('anthropic-beta', 'N/A')}")
        assert strategy_llm.model == "claude-haiku-4-5-20251001", f"Expected claude-haiku-4-5-20251001, got {strategy_llm.model}"
    except Exception as e:
        print(f"   âŒ Error: {e}")

    # 4. Portfolio/Risk LLM í™•ì¸
    print("\n4. Portfolio/Risk Agent LLM (Claude Haiku 4.5 + ìºì‹±):")
    try:
        portfolio_risk_llm = get_portfolio_risk_llm(temperature=0, max_tokens=100)
        print(f"   âœ… Model: {portfolio_risk_llm.model}")
        print(f"   âœ… Type: {type(portfolio_risk_llm).__name__}")
        print(f"   âœ… ìºì‹±: {portfolio_risk_llm.default_headers.get('anthropic-beta', 'N/A')}")
        assert portfolio_risk_llm.model == "claude-haiku-4-5-20251001", f"Expected claude-haiku-4-5-20251001, got {portfolio_risk_llm.model}"
    except Exception as e:
        print(f"   âŒ Error: {e}")

    # 5. Default Agent LLM í™•ì¸
    print("\n5. Trading + ê¸°íƒ€ Agent LLM (gpt-5-chat-latest):")
    try:
        default_llm = get_default_agent_llm(temperature=0, max_tokens=100)
        model_name = getattr(default_llm, 'model', None) or getattr(default_llm, 'model_name', None)
        print(f"   âœ… Model: {model_name}")
        print(f"   âœ… Type: {type(default_llm).__name__}")
        assert model_name == "gpt-5-chat-latest", f"Expected gpt-5-chat-latest, got {model_name}"
    except Exception as e:
        print(f"   âŒ Error: {e}")

    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  LLM ì„¤ì • ê²€ì¦ ì™„ë£Œ - ë¹„ìš© ìµœì í™” ì™„ë£Œ!")
    print("=" * 80)
    print("\nğŸ“Š ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ í• ë‹¹ (í”„ë¡¬í”„íŠ¸ ìºì‹± ì ìš©):")
    print("  ğŸ’° Claude ì—ì´ì „íŠ¸ (Haiku 4.5 + ìºì‹±):")
    print("     - Router Agent         : claude-haiku-4-5-20251001")
    print("     - Research Agent       : claude-haiku-4-5-20251001")
    print("     - Strategy Agent       : claude-haiku-4-5-20251001")
    print("     - Portfolio Agent      : claude-haiku-4-5-20251001")
    print("     - Risk Agent           : claude-haiku-4-5-20251001")
    print("\n  âš¡ OpenAI ì—ì´ì „íŠ¸ (gpt-5-chat-latest):")
    print("     - Trading Agent        : gpt-5-chat-latest")
    print("     - Monitoring Agent     : gpt-5-chat-latest")
    print("     - Report Gen Agent     : gpt-5-chat-latest")
    print("\n  ğŸ¯ ë¹„ìš© ì ˆê° íš¨ê³¼:")
    print("     - Sonnet â†’ Haiku ë³€ê²½ìœ¼ë¡œ ~90% ë¹„ìš© ì ˆê°")
    print("     - í”„ë¡¬í”„íŠ¸ ìºì‹±ìœ¼ë¡œ ì¶”ê°€ 90% ë¹„ìš© ì ˆê° (ë°˜ë³µ í˜¸ì¶œ ì‹œ)")
    print("     - ì´ ì˜ˆìƒ ë¹„ìš© ì ˆê°: ~99% (ìºì‹œ íˆíŠ¸ ì‹œ)")


if __name__ == "__main__":
    asyncio.run(test_llm_models())
